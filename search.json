[
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#an-ontology-of-ai",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#an-ontology-of-ai",
    "title": "AI in the Oncology Service Line",
    "section": "An Ontology of AI",
    "text": "An Ontology of AI"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#ai-vs.-ml-vs.-deep-learning",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#ai-vs.-ml-vs.-deep-learning",
    "title": "AI in the Oncology Service Line",
    "section": "AI vs. ML vs. Deep Learning",
    "text": "AI vs. ML vs. Deep Learning\n\n\nArtificialIntelligence\n\n\nMachineLearning\n\n\nDeepLearning"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#ai-vs.-ml-vs.-deep-learning-1",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#ai-vs.-ml-vs.-deep-learning-1",
    "title": "AI in the Oncology Service Line",
    "section": "AI vs. ML vs. Deep Learning",
    "text": "AI vs. ML vs. Deep Learning\n\n\nArtificialIntelligence\n\n\nMachineLearning\n\n\nDeepLearning"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#framework",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#framework",
    "title": "AI in the Oncology Service Line",
    "section": "Framework",
    "text": "Framework\n\n\n\n\nA schematic framework for organizing workstreams (orange boxes), domains (blue boxes), and work products and tasks (green ovals). Domains (vertical dimension) capture semi-independent organizations, each with largely independent use cases, budgets and business plans, priorities, and leadership. The workstreams (horizontal dimension) will often require similar or overlapping expertise, and can serve as knowledge resources to provide synergy and uniformity in implementation across domains.\n\n\nhttps://seandavi.github.io/campus-llm-kb/framework.html"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#vision-statement",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#vision-statement",
    "title": "AI in the Oncology Service Line",
    "section": "Vision Statement",
    "text": "Vision Statement\n\nLLMs must be used in a manner consistent with the mission, vision, and values of the academic hospital system.\nThe use of LLMs must align with relevant legal and regulatory requirements, including but not limited to data privacy, security, and intellectual property laws.\nThe deployment of LLMs should prioritize patient safety, privacy, and wellbeing.\nLLMs must be used in a transparent manner, with users understanding the capabilities and limitations of the technology.\nContinuous improvement and evaluation of LLM usage should be prioritized to ensure ongoing alignment with organizational goals."
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#patients",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#patients",
    "title": "AI in the Oncology Service Line",
    "section": "Patients",
    "text": "Patients\n\nLLMs should be used to augment patient care and improve outcomes, without replacing the human touch and empathy of healthcare providers.\nPatients must be informed about the use of LLMs in their care, and they should have the option to opt out if desired.\nPatient data used in LLM applications must be anonymized, encrypted, and securely stored to protect patient privacy."
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#healthcare-providers",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#healthcare-providers",
    "title": "AI in the Oncology Service Line",
    "section": "Healthcare Providers",
    "text": "Healthcare Providers\n\nLLMs should be deployed to enhance clinical decision-making and efficiency without undermining the autonomy and expertise of healthcare providers.\nAdequate training and support should be provided to healthcare providers to ensure proper use and understanding of LLMs.\nFeedback from healthcare providers must be regularly solicited to improve LLM performance and usability."
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#researchers",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#researchers",
    "title": "AI in the Oncology Service Line",
    "section": "Researchers",
    "text": "Researchers\n\nThe use of LLMs in research must adhere to ethical standards, including obtaining informed consent and minimizing potential harm.\nCollaboration between researchers and LLM developers should be encouraged to drive innovation and address specific research needs.\nResearch involving LLMs should be transparent and reproducible, with results and methodologies made available to the wider scientific community."
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#administrators-and-support-staff",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#administrators-and-support-staff",
    "title": "AI in the Oncology Service Line",
    "section": "Administrators and Support Staff",
    "text": "Administrators and Support Staff\n\nLLMs should be deployed in administrative and support functions to improve efficiency, reduce costs, and enhance the overall quality of service.\nStaff should receive appropriate training and support to understand and utilize LLMs effectively.\nEmployee feedback should be actively sought to identify areas of improvement and potential new applications for LLMs."
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#monitoring-and-compliance",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#monitoring-and-compliance",
    "title": "AI in the Oncology Service Line",
    "section": "Monitoring and Compliance",
    "text": "Monitoring and Compliance\n\nA designated LLM Steering Committee, comprising representatives from various stakeholder groups, will be responsible for monitoring and enforcing compliance with this policy.\nPeriodic audits and assessments will be conducted to ensure adherence to this policy and identify areas for improvement.\nPolicy violations may result in disciplinary action, up to and including termination of employment or access to LLMs"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-1-alleviate-health-disparities",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-1-alleviate-health-disparities",
    "title": "AI in the Oncology Service Line",
    "section": "Principle 1: Alleviate Health Disparities",
    "text": "Principle 1: Alleviate Health Disparities\n\nAI tools must be intentionally designed to reduce known disparities\nKey strategies:\n\nEnsure disadvantaged groups have equal access and benefit\nPreferentially design tools for disadvantaged populations\n\nConsider:\n\nTraining on balanced, unbiased datasets\nUsing accessible, routinely collected data points\nDesigning for low-resource settings\nEnsuring access to follow-up care"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-2-report-clinically-meaningful-outcomes",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-2-report-clinically-meaningful-outcomes",
    "title": "AI in the Oncology Service Line",
    "section": "Principle 2: Report Clinically Meaningful Outcomes",
    "text": "Principle 2: Report Clinically Meaningful Outcomes\n\nOutcomes must align with established clinical metrics of success\nConsider:\n\nEvolution of outcome measures over time\nCurrent standards in the field\nBoth short and long-term metrics\nClinician evaluation needs\n\nTools must enable assessment of:\n\nAccuracy\nFairness\nRisks\nHealthcare value\nInterpretability"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-3-reduce-overdiagnosis-and-overtreatment",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-3-reduce-overdiagnosis-and-overtreatment",
    "title": "AI in the Oncology Service Line",
    "section": "Principle 3: Reduce Overdiagnosis and Overtreatment",
    "text": "Principle 3: Reduce Overdiagnosis and Overtreatment\n\nBalance sensitivity with specificity\nConsider:\n\nDefinition of overdiagnosis in specific context\nPhysical, emotional, and financial costs\nEvolution of disease understanding\nDisease progression patterns\n\nDesign tools to:\n\nDifferentiate disease subtypes\nTailor interventions to disease severity\nMinimize unnecessary treatment"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-4-have-high-healthcare-value",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-4-have-high-healthcare-value",
    "title": "AI in the Oncology Service Line",
    "section": "Principle 4: Have High Healthcare Value",
    "text": "Principle 4: Have High Healthcare Value\n\nDeliver better outcomes for same cost OR same outcomes for less cost\nConsider:\n\nImplementation costs\nMaintenance costs\nUpdate costs\nError costs (immediate and downstream)\nResource allocation priorities\nHealthcare system capacity\n\nAvoid diverting resources from higher-priority areas"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-5-incorporate-biography",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-5-incorporate-biography",
    "title": "AI in the Oncology Service Line",
    "section": "Principle 5: Incorporate Biography",
    "text": "Principle 5: Incorporate Biography\n\nConsider patient’s lived experience beyond biology\nInclude factors such as:\n\nSocial exposures\nStructural conditions\nEnvironmental exposures\nEmotional states\nAllostatic load\nAccess to care\n\nStart with available data:\n\nZip codes\nSocioeconomic scales\nGeospatial information\n\nPlan to improve resolution over time"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-6-be-easily-tailored-to-local-population",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-6-be-easily-tailored-to-local-population",
    "title": "AI in the Oncology Service Line",
    "section": "Principle 6: Be Easily Tailored to Local Population",
    "text": "Principle 6: Be Easily Tailored to Local Population\n\nFocus on local precision over broad generalizability\nDesign considerations:\n\nUse easily collected inputs\nEnsure reliable training features across populations\nEnable local retraining\nPublish open AI workflows\nProvide platforms for local model training\n\nRecognize limitations of generalizability across:\n\nPopulations\nHealthcare systems\nTime periods"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-7-promote-a-learning-healthcare-system",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-7-promote-a-learning-healthcare-system",
    "title": "AI in the Oncology Service Line",
    "section": "Principle 7: Promote a Learning Healthcare System",
    "text": "Principle 7: Promote a Learning Healthcare System\n\nBuild continuous learning into design\nInclude:\n\nRegular evaluation mechanisms\nPerformance standards\nTimeframes for assessment\nIntegration of new knowledge\n\nAnalyze:\n\nWho the tool doesn’t work for\nWhy it doesn’t work\nImpact on patients\nImpact on healthcare system\n\nProvide framework for improvement"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-8-facilitate-shared-decision-making",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#principle-8-facilitate-shared-decision-making",
    "title": "AI in the Oncology Service Line",
    "section": "Principle 8: Facilitate Shared Decision-Making",
    "text": "Principle 8: Facilitate Shared Decision-Making\n\nEnable understanding of AI decisions\nDesign considerations:\n\nUse explainable algorithms\nPrioritize interpretability\nConsider simpler algorithms\nGenerate continuous scores vs. fixed thresholds\n\nSupport:\n\nPatient understanding\nProvider understanding\nIntegration of patient values\nRisk preference considerations"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#implementation-considerations",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#implementation-considerations",
    "title": "AI in the Oncology Service Line",
    "section": "Implementation Considerations",
    "text": "Implementation Considerations\n\n\n\nhttps://seandavi.github.io/campus-llm-kb/implementation.html"
  },
  {
    "objectID": "2024-10-28-ai-ml-oncology-service-line/index.html#local-concerns",
    "href": "2024-10-28-ai-ml-oncology-service-line/index.html#local-concerns",
    "title": "AI in the Oncology Service Line",
    "section": "Local Concerns",
    "text": "Local Concerns\n\nData classification\nAccess to AI tools\nUCHealth/University partnership\nResource allocation\nTraining and support\nPrioritization of projects\nCommercial partnerships\nOversight and governance"
  },
  {
    "objectID": "word-embedding-exercises.html",
    "href": "word-embedding-exercises.html",
    "title": "Experiments in Word Embeddings",
    "section": "",
    "text": "Recall that word embeddings are a way of representing words as vectors in a high-dimensional space. The idea is that words that are similar in meaning should be close together in this space. Word embeddings are often used as a way of representing words in natural language processing tasks, such as sentiment analysis, machine translation, and named entity recognition. Figure 1 schematically illustrates how words are represented in a vector space.\n\n\n\n\n\n\nFigure 1: Linear combinations of dimensions in vector space correlate with the semantic and syntactic roles of the words in the corpus1. For illustration purposes, dimension d1 in the figure has a high positive correlation with living beings. A properly tuned word embedding model will map words with similar semantic or syntactic roles to adjacent regions in vector space. This property can be visualized through dimensionality reduction techniques such as t-SNE or PCA. Cultural concepts are also apparent in vector space as consistent offsets between vector representations of words sharing a particular relationship. For instance, in the bottom right of the figure, the dotted vector represents a gender regularity that goes from masculinity to femininity.\n\n\n\nIn this set of experiments, we’ll be using some online tools that allow us to explore word embeddings. We’ll be using the TensorFlow Embedding Projector and the Word2Vec tool from Google.\n\n\nThe TensorFlow Embedding Projector is a web-based tool that allows you to visualize word embeddings in a 3D space. You can use it to explore the relationships between words and see how they are clustered together. Navigate to the TensorFlow Embedding Projector and experiment a bit.\n\nBy mousing over the points in the 3D space, you can see the words that are closest to a given word. You can also search for a specific word and see how it is related to other words in the space. If you click on a word, you can see a list of the words that are closest to it (based on cosine similarity in the embedding space, not necessarily in the 2D projection).\n\n\n\n\n\nIn this page, you can supply a word and the tool will find words that are similar in meaning. The “model” choice is based on the text that was used to train the embeddings (eg. Wikipedia, Google News, etc.). The numbers next to the words are the cosine similarity between the input word and the word in the list.\nExercise: Navigate to http://vectors.nlpl.eu/explore/embeddings/en/associates/ and experiment a bit.\n\n\n\nThis little tool allows you to visualize word embeddings in 2D. You can see how words are related to each other based on their embeddings. You’ll supply a list of words and the tool will show you how they are related to each other using TSNE or PCA (these are dimensionality reduction techniques that allow you to visualize high-dimensional data in 2D). The “model” choice is based on the text that was used to train the embeddings (eg. Wikipedia, Google News, etc.).\nExercise: Navigate to http://vectors.nlpl.eu/explore/embeddings/en/visual/ and experiment a bit.\n\n\n\n\nCalculate ratios, such as «find a word D related to the word C in the same way as the word A is related to the word B». An example is given in the placeholder: which word is in the same relation to the word «father» as «daughter» is to «mother»? The answer is «son». The model calculates the difference between the vectors of «mother» and «daughter» and adds it to the vector of «father». After doing so, the word with the closest vector to the result is output, which in this case is «son».\nSo, what does the difference between the vectors of «mother» and «daughter» represent? It represents the concept of a parent-child relationship. By adding this difference to the vector of «father», the model is looking for a word that is related to «father» in the same way that «daughter» is related to «mother». In this case, the answer is «son».\nExercise: Navigate to http://vectors.nlpl.eu/explore/embeddings/en/calculator/ and experiment a bit, perhaps trying some of the examples from Table 1.\nA few examples to try:\n\n\n\nTable 1: Some examples to try in the semantic calculator. What will be the result for word 4?\n\n\n\n\n\nWord 1\nWord 2\nWord 3\nWord 4\n\n\n\n\ndog\npuppy\ncat\n?\n\n\nking\nman\nqueen\n?\n\n\ncat\nkitten\nhorse\n?\n\n\nking\nboyfriend\nqueen\n?\n\n\nheart\nlungs\nstomach\n?"
  },
  {
    "objectID": "word-embedding-exercises.html#tensorflow-embedding-projector",
    "href": "word-embedding-exercises.html#tensorflow-embedding-projector",
    "title": "Experiments in Word Embeddings",
    "section": "",
    "text": "The TensorFlow Embedding Projector is a web-based tool that allows you to visualize word embeddings in a 3D space. You can use it to explore the relationships between words and see how they are clustered together. Navigate to the TensorFlow Embedding Projector and experiment a bit.\n\nBy mousing over the points in the 3D space, you can see the words that are closest to a given word. You can also search for a specific word and see how it is related to other words in the space. If you click on a word, you can see a list of the words that are closest to it (based on cosine similarity in the embedding space, not necessarily in the 2D projection)."
  },
  {
    "objectID": "word-embedding-exercises.html#webvectors",
    "href": "word-embedding-exercises.html#webvectors",
    "title": "Experiments in Word Embeddings",
    "section": "",
    "text": "In this page, you can supply a word and the tool will find words that are similar in meaning. The “model” choice is based on the text that was used to train the embeddings (eg. Wikipedia, Google News, etc.). The numbers next to the words are the cosine similarity between the input word and the word in the list.\nExercise: Navigate to http://vectors.nlpl.eu/explore/embeddings/en/associates/ and experiment a bit.\n\n\n\nThis little tool allows you to visualize word embeddings in 2D. You can see how words are related to each other based on their embeddings. You’ll supply a list of words and the tool will show you how they are related to each other using TSNE or PCA (these are dimensionality reduction techniques that allow you to visualize high-dimensional data in 2D). The “model” choice is based on the text that was used to train the embeddings (eg. Wikipedia, Google News, etc.).\nExercise: Navigate to http://vectors.nlpl.eu/explore/embeddings/en/visual/ and experiment a bit.\n\n\n\n\nCalculate ratios, such as «find a word D related to the word C in the same way as the word A is related to the word B». An example is given in the placeholder: which word is in the same relation to the word «father» as «daughter» is to «mother»? The answer is «son». The model calculates the difference between the vectors of «mother» and «daughter» and adds it to the vector of «father». After doing so, the word with the closest vector to the result is output, which in this case is «son».\nSo, what does the difference between the vectors of «mother» and «daughter» represent? It represents the concept of a parent-child relationship. By adding this difference to the vector of «father», the model is looking for a word that is related to «father» in the same way that «daughter» is related to «mother». In this case, the answer is «son».\nExercise: Navigate to http://vectors.nlpl.eu/explore/embeddings/en/calculator/ and experiment a bit, perhaps trying some of the examples from Table 1.\nA few examples to try:\n\n\n\nTable 1: Some examples to try in the semantic calculator. What will be the result for word 4?\n\n\n\n\n\nWord 1\nWord 2\nWord 3\nWord 4\n\n\n\n\ndog\npuppy\ncat\n?\n\n\nking\nman\nqueen\n?\n\n\ncat\nkitten\nhorse\n?\n\n\nking\nboyfriend\nqueen\n?\n\n\nheart\nlungs\nstomach\n?"
  },
  {
    "objectID": "word-embedding-exercises.html#footnotes",
    "href": "word-embedding-exercises.html#footnotes",
    "title": "Experiments in Word Embeddings",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://doi.org/10.1371/journal.pone.0231189↩︎"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#center",
    "href": "2023-11-03-Monroe-AI-ML/index.html#center",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Overview",
    "text": "Overview\n\n\n\nBrief history and background\nWhat are these things?\nMachine learning\nBiases and ethics"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#brief-history",
    "href": "2023-11-03-Monroe-AI-ML/index.html#brief-history",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Brief History",
    "text": "Brief History\n\n\nhttps://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#the-hype-cycle",
    "href": "2023-11-03-Monroe-AI-ML/index.html#the-hype-cycle",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "The hype cycle",
    "text": "The hype cycle\n\nThe Gartner Hype Cycle."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#the-hype-cycle-circa-2016",
    "href": "2023-11-03-Monroe-AI-ML/index.html#the-hype-cycle-circa-2016",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "The hype cycle (circa 2016)",
    "text": "The hype cycle (circa 2016)\n\nThe Gartner Hype Cycle."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#what-is-artificial-intelligence",
    "href": "2023-11-03-Monroe-AI-ML/index.html#what-is-artificial-intelligence",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "What is Artificial Intelligence?",
    "text": "What is Artificial Intelligence?\nThe theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#what-is-machine-learning",
    "href": "2023-11-03-Monroe-AI-ML/index.html#what-is-machine-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\nThe study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning systems give the computer the ability to learn without being explicitly programmed rules."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#what-is-deep-learning",
    "href": "2023-11-03-Monroe-AI-ML/index.html#what-is-deep-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "What is Deep Learning?",
    "text": "What is Deep Learning?\nMachine learning algorithms that are inspired by the structure and function of the brain. Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is often unstructured (i.e., text or images)."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#ai-vs.-ml-vs.-deep-learning",
    "href": "2023-11-03-Monroe-AI-ML/index.html#ai-vs.-ml-vs.-deep-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "AI vs. ML vs. Deep Learning",
    "text": "AI vs. ML vs. Deep Learning\n\n\nArtificialIntelligence\n\n\nMachineLearning\n\n\nDeepLearning"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#ai-vs.-ml-vs.-deep-learning-1",
    "href": "2023-11-03-Monroe-AI-ML/index.html#ai-vs.-ml-vs.-deep-learning-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "AI vs. ML vs. Deep Learning",
    "text": "AI vs. ML vs. Deep Learning\n\n\nArtificialIntelligence\n\n\nMachineLearning\n\n\nDeepLearning"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#applications-in-healthcare",
    "href": "2023-11-03-Monroe-AI-ML/index.html#applications-in-healthcare",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Applications in healthcare",
    "text": "Applications in healthcare\n\nThe data types considered in the artificial intelligence artificial (AI) literature. The comparison is obtained through searching the diagnosis techniques in the AI literature on the PubMed database(Jiang et al. 2017, fig. 1)."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#applications-in-healthcare-1",
    "href": "2023-11-03-Monroe-AI-ML/index.html#applications-in-healthcare-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Applications in healthcare",
    "text": "Applications in healthcare\n\nThe leading 10 disease types considered in the artificial intelligence (AI) literature. The first vocabularies in the disease names are displayed. The comparison is obtained through searching the disease types in the AI literature on PubMed (Jiang et al. 2017, fig. 3)."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#applications-in-healthcare-2",
    "href": "2023-11-03-Monroe-AI-ML/index.html#applications-in-healthcare-2",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Applications in healthcare",
    "text": "Applications in healthcare\n\nfrom (Challen et al. 2019)"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#classes-of-machine-learning",
    "href": "2023-11-03-Monroe-AI-ML/index.html#classes-of-machine-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Classes of Machine Learning",
    "text": "Classes of Machine Learning\n\nBroad classes of machine learning."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#a-map-of-machine-learning-approaches",
    "href": "2023-11-03-Monroe-AI-ML/index.html#a-map-of-machine-learning-approaches",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "A map of machine learning approaches",
    "text": "A map of machine learning approaches\n\n\nhttps://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#supervised-learning",
    "href": "2023-11-03-Monroe-AI-ML/index.html#supervised-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#supervised-learning-1",
    "href": "2023-11-03-Monroe-AI-ML/index.html#supervised-learning-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\n\nSupervised learning."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#supervised-learning-2",
    "href": "2023-11-03-Monroe-AI-ML/index.html#supervised-learning-2",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\n\nSupervised learning."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#supervised-learning-3",
    "href": "2023-11-03-Monroe-AI-ML/index.html#supervised-learning-3",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\n\nSupervised learning."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#classification",
    "href": "2023-11-03-Monroe-AI-ML/index.html#classification",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Classification",
    "text": "Classification"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#regression",
    "href": "2023-11-03-Monroe-AI-ML/index.html#regression",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Regression",
    "text": "Regression\n\nApplication of regression to predict eutrophil count using the signatures learned from public databases(Oh et al. 2022, fig. 4)"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#developing-a-model",
    "href": "2023-11-03-Monroe-AI-ML/index.html#developing-a-model",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Developing a model",
    "text": "Developing a model\n\nDevelop question!!!\nCollect data\nSplit data into training and test\nTrain model\n\nestimating model parameters (i.e. training models)\ndetermining the values of tuning parameters that cannot be directly calculated from the data\n\nTest model\n\ncalculating the performance of the final model that will generalize to new data\n\nPossibly validate model\nDeploy"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#algorithms-for-supervised-learning",
    "href": "2023-11-03-Monroe-AI-ML/index.html#algorithms-for-supervised-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nLinear regression."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#algorithms-for-supervised-learning-1",
    "href": "2023-11-03-Monroe-AI-ML/index.html#algorithms-for-supervised-learning-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nAnscombe’s Quartet\nhttps://en.wikipedia.org/wiki/Anscombe%27s_quartet"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#algorithms-for-supervised-learning-2",
    "href": "2023-11-03-Monroe-AI-ML/index.html#algorithms-for-supervised-learning-2",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nClassification and Regression Trees (CART)."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#algorithms-for-supervised-learning-3",
    "href": "2023-11-03-Monroe-AI-ML/index.html#algorithms-for-supervised-learning-3",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nK-nearest neighbor (kNN) algorithm."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#algorithms-for-supervised-learning-4",
    "href": "2023-11-03-Monroe-AI-ML/index.html#algorithms-for-supervised-learning-4",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nRandom Forests."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#algorithms-for-supervised-learning-5",
    "href": "2023-11-03-Monroe-AI-ML/index.html#algorithms-for-supervised-learning-5",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nDeep learning."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#applying-supervised-learning-algorithms",
    "href": "2023-11-03-Monroe-AI-ML/index.html#applying-supervised-learning-algorithms",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Applying Supervised Learning Algorithms",
    "text": "Applying Supervised Learning Algorithms\n\nThe mlr3 ecosystem in R."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#unsupervised-learning",
    "href": "2023-11-03-Monroe-AI-ML/index.html#unsupervised-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Unsupervised Learning",
    "text": "Unsupervised Learning\n\nUnsupervised learning."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#clustering",
    "href": "2023-11-03-Monroe-AI-ML/index.html#clustering",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nGene expression measurements."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#classes-of-unsupervised-learning-algorithms",
    "href": "2023-11-03-Monroe-AI-ML/index.html#classes-of-unsupervised-learning-algorithms",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Classes of unsupervised learning algorithms",
    "text": "Classes of unsupervised learning algorithms\n\n\n\n\n\nClustering.\n\n\n\n\n\n\nDimensionality reduction."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#clustering-1",
    "href": "2023-11-03-Monroe-AI-ML/index.html#clustering-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nThinking about similarities and differences"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#clustering-2",
    "href": "2023-11-03-Monroe-AI-ML/index.html#clustering-2",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#clustering-3",
    "href": "2023-11-03-Monroe-AI-ML/index.html#clustering-3",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#clustering-4",
    "href": "2023-11-03-Monroe-AI-ML/index.html#clustering-4",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#dimensionality-reduction",
    "href": "2023-11-03-Monroe-AI-ML/index.html#dimensionality-reduction",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\n\nSchematic PCA."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#dimensionality-reduction-1",
    "href": "2023-11-03-Monroe-AI-ML/index.html#dimensionality-reduction-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\n\nUsing dimensionality reduction to explore 22,000 dimensions of gene expression data on 280 samples.\nhttps://seandavi.github.io/ITR/geoquery_mds.html"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#machine-learning-review",
    "href": "2023-11-03-Monroe-AI-ML/index.html#machine-learning-review",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Machine Learning Review",
    "text": "Machine Learning Review\n\nSupervised Learning\n\nClassification\nRegression\n\nUnsupervised Learning\n\nClustering\nDimensionality Reduction"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#resources",
    "href": "2023-11-03-Monroe-AI-ML/index.html#resources",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Resources",
    "text": "Resources\n\nRecent reviews\n\nMachine Learning in Genomic Medicine: A Review of Computational Problems and Data Sets\nOpportunities And Obstacles For Deep Learning In Biology And Medicine\n\nBlogs and online materials\n\nhttps://blog.recast.ai/machine-learning-algorithms/\nhttps://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A\nhttps://www.youtube.com/c/joshstarmer\n\nMachine Learning in R\n\nhttps://www.datacamp.com/community/tutorials/machine-learning-in-r\nhttps://daviddalpiaz.github.io/r4sl/"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#ethical-challenges-in-ai-ml",
    "href": "2023-11-03-Monroe-AI-ML/index.html#ethical-challenges-in-ai-ml",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Ethical challenges in AI & ML",
    "text": "Ethical challenges in AI & ML\n\nHow do we address ethical and moral decisionmaking for individuals, groups, and society?\nhttps://sitn.hms.harvard.edu/flash/2017/hold-artificial-intelligence-accountable/"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#biases-in-aiml",
    "href": "2023-11-03-Monroe-AI-ML/index.html#biases-in-aiml",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Biases in AI/ML",
    "text": "Biases in AI/ML\n\nTypes and sources of bias in big data and AI/ML applications in healthcare (Norori et al. 2021). Bias in the medical field can be dissected along three directions: data-driven, algorithmic, and human."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#addressing-bias",
    "href": "2023-11-03-Monroe-AI-ML/index.html#addressing-bias",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Addressing Bias",
    "text": "Addressing Bias\n\n\n\n\n Open science practices can assist in moving toward fairness in AI for health care (Norori et al. 2021). These include:\n\nparticipant-centered development of AI algorithms and participatory science;\nresponsible data sharing and inclusive data standards to support interoperability;\ncode sharing, including sharing of AI algorithms that can synthesize underrepresented data to address bias and improve health outcomes.\n\n\nEach of these is harder and more expensive than it sounds."
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#complexity",
    "href": "2023-11-03-Monroe-AI-ML/index.html#complexity",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Complexity",
    "text": "Complexity"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#fda-and-regulation",
    "href": "2023-11-03-Monroe-AI-ML/index.html#fda-and-regulation",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "FDA and regulation",
    "text": "FDA and regulation"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#hipaa",
    "href": "2023-11-03-Monroe-AI-ML/index.html#hipaa",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "HIPAA",
    "text": "HIPAA"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#questions-and-discussion",
    "href": "2023-11-03-Monroe-AI-ML/index.html#questions-and-discussion",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Questions and Discussion",
    "text": "Questions and Discussion\n\nSean Davis\nhttps://seandavi.github.io\nhttps://twitter.com/seandavis12\nsean.2.davis@cuanschutz.edu"
  },
  {
    "objectID": "2023-11-03-Monroe-AI-ML/index.html#references",
    "href": "2023-11-03-Monroe-AI-ML/index.html#references",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "References",
    "text": "References\n\n\n\n\nChallen, Robert, Joshua Denny, Martin Pitt, Luke Gompels, Tom Edwards, and Krasimira Tsaneva-Atanasova. 2019. “Artificial Intelligence, Bias and Clinical Safety.” BMJ Quality & Safety 28 (3): 231–37.\n\n\nJiang, Fei, Yong Jiang, Hui Zhi, Yi Dong, Hao Li, Sufeng Ma, Yilong Wang, Qiang Dong, Haipeng Shen, and Yongjun Wang. 2017. “Artificial Intelligence in Healthcare: Past, Present and Future.” Stroke and Vascular Neurology 2 (4): 230–43. https://doi.org/10.1136/svn-2017-000101.\n\n\nNorori, Natalia, Qiyang Hu, Florence Marcelle Aellen, Francesca Dalia Faraci, and Athina Tzovara. 2021. “Addressing Bias in Big Data and AI for Health Care: A Call for Open Science.” Patterns (New York, N.Y.) 2 (10): 100347. https://doi.org/10.1016/j.patter.2021.100347.\n\n\nOh, Sehyun, Ludwig Geistlinger, Marcel Ramos, Daniel Blankenberg, Marius van den Beek, Jaclyn N Taroni, Vincent J Carey, Casey S Greene, Levi Waldron, and Sean Davis. 2022. “GenomicSuperSignature Facilitates Interpretation of RNA-seq Experiments Through Robust, Efficient Comparison to Public Databases.” Nature Communications 13 (1): 3695. https://doi.org/10.1038/s41467-022-31411-3."
  },
  {
    "objectID": "2023-11-27-CUNY-json-data/talk.html",
    "href": "2023-11-27-CUNY-json-data/talk.html",
    "title": "Javascript Object Notation (JSON)",
    "section": "",
    "text": "It is common to want to extract data from an online database, extract information from a web page, or interact with a web application. Doing so requires an understanding of:\n\nHow the web works and how to interact with it.\nHow computers represent the data when it is transmitted over the web.\nHow to parse the data into a format that can be used by a computer.\nHow to extract the information that you want from the data.\nHow to use the extracted information in your own application.\nHow to automate the process of extracting the information."
  },
  {
    "objectID": "2023-11-27-CUNY-json-data/talk.html#motivation",
    "href": "2023-11-27-CUNY-json-data/talk.html#motivation",
    "title": "Javascript Object Notation (JSON)",
    "section": "",
    "text": "It is common to want to extract data from an online database, extract information from a web page, or interact with a web application. Doing so requires an understanding of:\n\nHow the web works and how to interact with it.\nHow computers represent the data when it is transmitted over the web.\nHow to parse the data into a format that can be used by a computer.\nHow to extract the information that you want from the data.\nHow to use the extracted information in your own application.\nHow to automate the process of extracting the information."
  },
  {
    "objectID": "2023-11-27-CUNY-json-data/talk.html#how-does-the-web-work",
    "href": "2023-11-27-CUNY-json-data/talk.html#how-does-the-web-work",
    "title": "Javascript Object Notation (JSON)",
    "section": "How does the web work?",
    "text": "How does the web work?\nThe Web (or World Wide Web, as it was originally called), works by using a client-server model. A client (usually a web browser) sends a request to a server (most often a web server like Apache, Nginx, IIS, Tomcat, etc.) The server then sends a response back to the client. The response contains the requested content, or an error message if an error occurred. The content of the response is usually HTML, but it can also be JSON, XML, or some other format.\n\n\n\n\n\n\nsequenceDiagram\n    autonumber\n    participant User\n    participant Client\n    participant Server\n    User-&gt;&gt;Client: URL in browser\n    Client-&gt;&gt;Server: Request\n    Server-&gt;&gt;Client: Response\n    Client-&gt;&gt;User: HTML page\n    User-&gt;&gt;Client: Specify search terms and click search button\n    Client-&gt;&gt;Server: Request\n    Server-&gt;&gt;Client: Response\n    Client-&gt;&gt;User: HTML page\n\n\n\n\nFigure 1: The interaction between a user, a client, and a server.\n\n\n\n\n\nFigure 1 shows a sequence diagram of the interaction between a user, a client, and a server. Let’s walk through the steps on the sequence diagram by navigating to the European PMC website https://europepmc.org/ (see Figure 2, point 1). The browser sends a request to the server (see Figure 2, point 2). The server then sends a response back to the browser (see Figure 2, point 3). The response contains the requested content, or an error message if an error occurred. In this case, the response is an HTML document that contains the content of the website (see Figure 2, point 4).\n\n\n\n\n\n\nFigure 2: Europe PMC provides comprehensive access to life sciences literature from trusted sources. It’s available to anyone, anywhere for free. With Europe PMC you can search and read 43.2 million publications, preprints and other documents enriched with links to supporting data, reviews, protocols, and other relevant resources.\n\n\n\nLet’s do a search for studies related to COVID-19 vaccinations. This isn’t hard, but it does require a little trickery to ensure that the search is interpreted correctly by the server. Paste the following into the search box and click the search button (see Figure 2, point 5).\nTITLE:\"vaccination\" AND TITLE:\"covid-19\"\nThe browser sends a request to the server (see Figure 2, point 6). The server then does the search and sends a response back to the browser (see Figure 2, point 7). Finally, the browser displays the search results (see Figure 2, point 8).\n\n\n\n\n\n\nFigure 3: The HTML response to the query for “vaccination” and “Covid-19”.\n\n\n\nWe can also do some of the work of the browser by sending a request directly to the server. In fact, you can paste that value into your browser to perform the search again without using the search box. The server then sends a response back to the browser and the browser displays the search results.\nPaste this into the browser address bar and hit enter:\nhttps://europepmc.org/search?query=TITLE:%22vaccination%22+AND+TITLE:%22covid-19%22\nHTML is a markup language that is used to structure content on the web and is the most common format for transmitting data between a server and a web application. However the resulting “page” is not very useful for a computer. If we wanted to use a computer to understand this response (e.g., to extract the number of results), we would need to write code to parse the HTML, which looks like this:\n\n\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\" prefix=\"dc: http://purl.org/dc/elements/1.1/#; dcterms: http://purl.org/dc/terms/#\"&gt;\n&lt;head&gt;&lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt;&lt;meta charset=\"utf-8\"&gt;&lt;meta name=\"viewport\" content=\"width=device-width\"&gt;&lt;script type=\"text/javascript\" src=\"./wicket/resource/org.apache.wicket.resource.JQueryResourceReference/jquery/jquery-1.11.1.min-ver-8101D596B2B8FA35FE3A634EA342D7C3.js\"&gt;&lt;/script&gt;\n&lt;link rel=\"stylesheet\" type=\"text/css\" href=\"/css_min/min/orcid-min.css?v=1210\" /&gt;\n&lt;script type=\"text/javascript\" src=\"./wicket/resource/org.europepmc.account.AccountSigninPanel/AccoutSigninPanel-ver-23536C62407C81CFCDCB80EBF689D4C9.js\"&gt;&lt;/script&gt;\n&lt;script type=\"text/javascript\" src=\"./wicket/resource/org.apache.wicket.ajax.AbstractDefaultAjaxBehavior/res/js/wicket-event-jquery.min-ver-F070EDFAD7E5A1BD9662F385470094FF.js\"&gt;&lt;/script&gt;\n&lt;script type=\"text/javascript\" src=\"./wicket/resource/org.apache.wicket.ajax.AbstractDefaultAjaxBehavior/res/js/wicket-ajax-jquery.min-ver-1D4EE56166B3A1106E05B678CC2AB1EF.js\"&gt;&lt;/script&gt;\n&lt;script type=\"text/javascript\" src=\"./wicket/resource/org.apache.wicket.extensions.ajax.markup.html.modal.ModalWindow/res/modal.min-ver-E43C9229F7812A6259B89C7E5B5028FB.js\"&gt;&lt;/script&gt;\n&lt;link rel=\"stylesheet\" type=\"text/css\" href=\"./wicket/resource/org.apache.wicket.extensions.ajax.markup.html.modal.ModalWindow/res/modal.min-ver-E99D4201F0F6C5D3081AD42ACB1F22C2.css\" /&gt;\n&lt;script type=\"text/javascript\" id=\"wicket-ajax-base-url\"&gt;\n/*&lt;![CDATA[*/\nWicket.Ajax.baseUrl=\"search?query=TITLE:%22nhanes%22+AND+TITLE:%22covid-19%22\";\n/*]]&gt;*/\n&lt;/script&gt;\n\n&lt;style id=\"uk-bl-ukpmc-web-pages-template-TemplatePage-0\"&gt;\n/*&lt;![CDATA[*/\n\n#search-feature-link {\ndisplay: none;\n}\n@media only screen and (max-width: 800px) {\n#search-feature-link {\ndisplay: block;\n}\n}\n\n/*]]&gt;*/\n&lt;/style&gt;\n&lt;script type=\"text/javascript\" src=\"./wicket/resource/uk.bl.ukpmc.web.pages.template.TemplatePage/TemplatePage-ver-540ECA69167ECC178EB8C919D0809EB3.js\"&gt;&lt;/script&gt;\n\n&lt;title&gt;Europe PMC&lt;/title&gt;\n&lt;link rel=\"stylesheet\" href=\"/template/font-awesome/css/all.min.css\"&gt;\n&lt;link rel=\"stylesheet\" href=\"/template/EPMC-iconfont/style.css?v=1210\"&gt;\n&lt;link rel=\"icon\" href=\"/images/favicon.ico\" type=\"image/x-icon\"&gt;\n&lt;link rel=\"alternate\" type=\"application/rss+xml\"\ntitle=\"Europe PMC: Popular articles\"\nhref=\"/Funders/RSS/MostViewedArticles.xml\"&gt;\n&lt;link rel=\"alternate\" type=\"application/rss+xml\"\ntitle=\"Europe PMC: Recent articles\"\nhref=\"/Funders/RSS/AllFunders.xml\"&gt;\n&lt;link rel=\"alternate\" type=\"application/rss+xml\"\ntitle=\"Europe PMC: Latest journals\"\nhref=\"/Funders/rss/NewJournals.xml\"&gt;\n&lt;link rel=\"alternate\" type=\"application/rss+xml\"\ntitle=\"Europe PMC: Content Holdings\"\nhref=\"/contentrss\"&gt;\n&lt;meta name=\"theme-color\" content=\"#666\"/&gt;\n&lt;meta name=\"author\" content=\"Europe PMC\"/&gt;\n&lt;meta name=\"owner\" content=\"Europe PMC\"/&gt;\n&lt;meta name=\"keywords\"\ncontent=\"Europe PMC, Europe PubMed Central, open access, research articles, journal articles, abstracts, full text, literature search, clinical guidelines, biological patents, life sciences, bioinformatics, biomedical research, citation search, biomedical journals, ORCIDs, text mining, citation networks, REST APIs \"/&gt;\n&lt;meta name=\"description\" content=\"Europe PMC is an archive of life sciences journal literature.\"/&gt;\n&lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=11\" /&gt;\n\n&lt;link rel=\"search\" type=\"application/opensearchdescription+xml\" title=\"Search Europe PMC\" href=\"/tools_epmc/opensearch_epmc.xml\"&gt;\n&lt;link rel=\"stylesheet\" type=\"text/css\" media=\"print, screen\" href=\"/template/jquery_ui.css?v=1210\"/&gt;\n&lt;link rel=\"stylesheet\" type=\"text/css\" media=\"screen\" href=\"/template/jquery_menu.css?v=1210\"/&gt;\n&lt;script type=\"text/javascript\" src=\"/template/yahoo-min.js?v=1210\"&gt;&lt;/script&gt;\n&lt;script type=\"text/javascript\" src=\"/template/dom-min.js?v=1210\"&gt;&lt;/script&gt;\n&lt;script type=\"text/javascript\" src=\"/template/enrichment.js?v=1210\"&gt;&lt;/script&gt;\n&lt;link rel=\"stylesheet\" type=\"text/css\" media=\"print, screen\" href=\"/template/enrichment.css?v=1210\"/&gt;\n&lt;script type=\"text/javascript\" src=\"/template/hoverIntent.js?v=1210\"&gt;&lt;/script&gt;\n&lt;script type=\"text/javascript\" src=\"/template/jquery.js?v=1210\"&gt;&lt;/script&gt;\n&lt;link rel=\"stylesheet\" type=\"text/css\" href=\"/template/ncbi/epmc.ncbi.css?v=1210\"/&gt;\n&lt;script type=\"text/javascript\" src=\"/template/epmc.js?v=1210\"&gt;&lt;/script&gt;\n&lt;link rel=\"stylesheet\" type=\"text/css\" href=\"/template/epmc_new.css?v=1210\"/&gt;"
  },
  {
    "objectID": "2023-11-27-CUNY-json-data/talk.html#introduction-to-json",
    "href": "2023-11-27-CUNY-json-data/talk.html#introduction-to-json",
    "title": "Javascript Object Notation (JSON)",
    "section": "Introduction to JSON",
    "text": "Introduction to JSON\nOur next step in understanding how to extract data from the web is to understand how computers represent the data when it is transmitted over the web.\nJSON, which is an abbreviation for Javascript Object Notation is a lightweight data interchange format that is easy for humans to read and write and easy for machines to parse and generate. It is often used to transmit data between a server and a web application. JSON was first specified by Douglas Crockford in the early 2000s. It emerged as a response to the need for a simpler, more lightweight data interchange format compared to XML or HTML.\nJSON is commonly used for data interchange between a server and a web application. It’s a popular format for representing configuration data and transmitting data between a server and a client, especially when the client is a computer program. JSON is also used for serializing and transmitting structured data over a network connection.\n\nStructure of JSON\nJSON data is represented as key-value pairs, similar to a dictionary in Python, a list in R, or an object in JavaScript. Data is written as name/value pairs, where the name (a string) is followed by a colon, and the value can be a string, number, object, array, boolean, or null.\n\n{\n  \"name\": \"John Doe\",\n  \"age\": 30,\n  \"city\": \"New York\",\n  \"isStudent\": false,\n  \"grades\": [90, 85, 92]\n}\n\nJSON supports nested structures, allowing for the representation of hierarchical and complex data.\n\n{\n  \"person\": {\n    \"name\": \"Alice\",\n    \"age\": 25,\n    \"address\": {\n      \"street\": \"123 Main St\",\n      \"city\": \"Cityville\",\n      \"zip\": \"12345\"\n    }\n  },\n  \"isStudent\": true\n}\n\n\n\nJSON and web APIs\nWeb APIs are a common way to interact with a web application. These APIs allow you to interact with a web application using a programming language like Python or R. Web APIs are often used to extract data from a web application, such as a database like Europe PMC.\nLet’s look at the same example we used above, but this time we will use the Europe PMC web API to extract the data.\n\n\n\n\n\n\nNote\n\n\n\nThe Europe PMC web API is documented at https://europepmc.org/RestfulWebService. The documentation provides examples of how to use the API to extract data from Europe PMC. For example, the Search API is documented at https://europepmc.org/RestfulWebService#!/Europe32PMC32Articles32RESTful32API/search.\n\n\nThe Europe PMC web API is a RESTful API, which means that it uses the HTTP protocol to send and receive data. The HTTP protocol is the same protocol that is used by web browsers to communicate with web servers. The HTTP protocol is a request-response protocol, which means that a client sends a request to a server and the server sends a response back to the client.\nLet’s use the Europe PMC web API to extract the number of results for the search for “vaccination” and “covid-19” and the first three results.\nThe URL for this search using the Europe PMC web API is:\nhttps://www.ebi.ac.uk/europepmc/webservices/rest/search?query=TITLE:%22vaccination%22+AND+TITLE:%22covid-19%22&format=json&pageSize=3\n\n\n\n\n\n\nTip\n\n\n\nJSON can be challenging to read and understand without formatting that renders the JSON more human-readable. When viewing JSON in a browser, the JSONVue extension for Chrome can be used to format JSON in the browser. You can also use the JSON Formatter website to format JSON by cutting and pasting the JSON into the website.\n\n\nEither install a JSON formatter extension for your browser or go to https://jsonformatter.org/ and paste the results from your web browser into the website."
  },
  {
    "objectID": "2023-11-27-CUNY-json-data/talk.html#working-with-json-in-r",
    "href": "2023-11-27-CUNY-json-data/talk.html#working-with-json-in-r",
    "title": "Javascript Object Notation (JSON)",
    "section": "Working with JSON in R",
    "text": "Working with JSON in R\nThe next steps in working with JSON from the web involve using a different client than a web browser. In this case, we will use R as our client.\nR has a number of packages that can be used to work with JSON, but we will focus on the jsonlite package.\nFirst, we need to install the package.\n\ninstall.packages(\"jsonlite\")\n\nThe jsonlite package provides a number of functions for working with JSON, but we will focus on the fromJSON() function, which converts JSON to an R object.\n\nlibrary(jsonlite)\nURL &lt;- \"https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=TITLE:%22vaccination%22+AND+TITLE:%22covid-19%22&format=json&pageSize=3\"\nr_result &lt;- jsonlite::fromJSON(URL)\nclass(r_result)\n\n[1] \"list\"\n\n\nThe fromJSON() function returns a list, which is a common data structure in R. Let’s look at the structure of the list in R.\n\nstr(r_result)\n\nList of 6\n $ version       : chr \"6.9\"\n $ hitCount      : int 14709\n $ nextCursorMark: chr \"AoIIQIz+rig1MTYwNDE3NA==\"\n $ nextPageUrl   : chr \"https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=TITLE:\\\"vaccination\\\" AND TITLE:\\\"covid-19\\\"&curs\"| __truncated__\n $ request       :List of 6\n  ..$ queryString: chr \"TITLE:\\\"vaccination\\\" AND TITLE:\\\"covid-19\\\"\"\n  ..$ resultType : chr \"lite\"\n  ..$ cursorMark : chr \"*\"\n  ..$ pageSize   : int 3\n  ..$ sort       : chr \"\"\n  ..$ synonym    : logi FALSE\n $ resultList    :List of 1\n  ..$ result:'data.frame':  3 obs. of  29 variables:\n  .. ..$ id                   : chr [1:3] \"39460358\" \"39220095\" \"39334217\"\n  .. ..$ source               : chr [1:3] \"MED\" \"MED\" \"MED\"\n  .. ..$ pmid                 : chr [1:3] \"39460358\" \"39220095\" \"39334217\"\n  .. ..$ doi                  : chr [1:3] \"10.3390/vaccines12101193\" \"10.1002/rcr2.70008\" \"10.1186/s12889-024-20133-4\"\n  .. ..$ title                : chr [1:3] \"Myocarditis Associated with COVID-19 Vaccination.\" \"Relapsing polychondritis after COVID-19 vaccination.\" \"Religious belongings and Covid-19 vaccination.\"\n  .. ..$ authorString         : chr [1:3] \"Florek K, Sokolski M.\" \"Ito K, Ogawa T, Igarashi S, Miyai K, Sato K, Kawana A, Kimizuka Y.\" \"Chakhunashvili K, Kvirkvelia E, Chakhunashvili DG.\"\n  .. ..$ journalTitle         : chr [1:3] \"Vaccines (Basel)\" \"Respirol Case Rep\" \"BMC Public Health\"\n  .. ..$ issue                : chr [1:3] \"10\" \"9\" \"1\"\n  .. ..$ journalVolume        : chr [1:3] \"12\" \"12\" \"24\"\n  .. ..$ pubYear              : chr [1:3] \"2024\" \"2024\" \"2024\"\n  .. ..$ journalIssn          : chr [1:3] \"2076-393x\" \"2051-3380\" \"1471-2458\"\n  .. ..$ pageInfo             : chr [1:3] \"1193\" \"e70008\" \"2585\"\n  .. ..$ pubType              : chr [1:3] \"review; journal article\" \"journal article; case reports; case-report\" \"research-article; journal article\"\n  .. ..$ isOpenAccess         : chr [1:3] \"N\" \"Y\" \"Y\"\n  .. ..$ inEPMC               : chr [1:3] \"N\" \"Y\" \"Y\"\n  .. ..$ inPMC                : chr [1:3] \"N\" \"Y\" \"Y\"\n  .. ..$ hasPDF               : chr [1:3] \"N\" \"Y\" \"Y\"\n  .. ..$ hasBook              : chr [1:3] \"N\" \"N\" \"N\"\n  .. ..$ hasSuppl             : chr [1:3] \"N\" \"N\" \"N\"\n  .. ..$ citedByCount         : int [1:3] 0 0 0\n  .. ..$ hasReferences        : chr [1:3] \"Y\" \"Y\" \"Y\"\n  .. ..$ hasTextMinedTerms    : chr [1:3] \"Y\" \"Y\" \"Y\"\n  .. ..$ hasDbCrossReferences : chr [1:3] \"N\" \"N\" \"N\"\n  .. ..$ hasLabsLinks         : chr [1:3] \"N\" \"Y\" \"N\"\n  .. ..$ hasTMAccessionNumbers: chr [1:3] \"N\" \"N\" \"N\"\n  .. ..$ firstIndexDate       : chr [1:3] \"2024-10-27\" \"2024-09-03\" \"2024-09-29\"\n  .. ..$ firstPublicationDate : chr [1:3] \"2024-10-19\" \"2024-08-30\" \"2024-09-27\"\n  .. ..$ pmcid                : chr [1:3] NA \"PMC11362975\" \"PMC11428539\"\n  .. ..$ fullTextIdList       :'data.frame':    3 obs. of  1 variable:\n  .. .. ..$ fullTextId:List of 3\n  .. .. .. ..$ : NULL\n  .. .. .. ..$ : chr \"PMC11362975\"\n  .. .. .. ..$ : chr \"PMC11428539\"\n\n\n\nCompare the structure of the list in R to the structure of the JSON in the browser.\nCompare the number of results in the JSON to the number of results in the R list.\nCompare the number of results in the R list to the number of results in the browser.\n\nWe can access individual elements of the list using the $ operator.\n\nr_result$hitCount\n\n[1] 14709\n\n\nAnd we can do the same for “nested” elements of the list.\n\nr_result$request$queryString\n\n[1] \"TITLE:\\\"vaccination\\\" AND TITLE:\\\"covid-19\\\"\"\n\n\nNote that the “important” information comes into R as a data.frame, but it is “nested” inside the list. Let’s pull it out of the list and assign it to a variable.\n\ntop3_articles &lt;- r_result$resultList$result\n\nLet’s not stop with the top 3 articles and instead get the top 1000 articles. To do so, we simply change our URL to request 1000 results.\n\nURL &lt;- \"https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=TITLE:%22vaccination%22+AND+TITLE:%22covid-19%22&format=json&pageSize=1000\"\nr_result &lt;- jsonlite::fromJSON(URL)\ntop1000_articles &lt;- r_result$resultList$result\n\nAnd now we can plot the number of articles by year.\n\nlibrary(ggplot2)\nggplot(top1000_articles, aes(x = pubYear)) +\n  geom_bar()"
  },
  {
    "objectID": "2023-11-27-CUNY-json-data/talk.html#dont-stop-there",
    "href": "2023-11-27-CUNY-json-data/talk.html#dont-stop-there",
    "title": "Javascript Object Notation (JSON)",
    "section": "Don’t stop there!",
    "text": "Don’t stop there!\nWe can also use the new large language models like ChatGPT to generate JSON structured data from text. Why would we want to do this? Well, it’s a way to automate the process of extracting information from text. Imagine a scenario where you have a large number of documents that you want to extract information from. You could use ChatGPT to automate the process of extracting the information from the documents and then read the JSON to get the information you want.\nI supplied the following to ChatGPT, taken from the NHANES website https://www.cdc.gov/nchs/nhanes/about_nhanes.htm:\nI'd like to structure the data in this document as JSON. Can you do so for me? \n\nAs in past health examination surveys, data will be collected on the prevalence of chronic conditions in the population. Estimates for previously undiagnosed conditions, as well as those known to and reported by respondents, are produced through the survey. Such information is a particular strength of the NHANES program.\n\nRisk factors, those aspects of a person’s lifestyle, constitution, heredity, or environment that may increase the chances of developing a certain disease or condition, will be examined. Smoking, alcohol consumption, sexual practices, drug use, physical fitness and activity, weight, and dietary intake will be studied. Data on certain aspects of reproductive health, such as use of oral contraceptives and breastfeeding practices, will also be collected.\n\nThe diseases, medical conditions, and health indicators to be studied include:\n\nAnemia\nCardiovascular disease\nDiabetes\nEnvironmental exposures\nEye diseases\nHearing loss\nInfectious diseases\nKidney disease\nNutrition\nObesity\nOral health\nOsteoporosis\nPhysical fitness and physical functioning\nReproductive history and sexual behavior\nRespiratory disease (asthma, chronic bronchitis, emphysema)\nSexually transmitted diseases\nVision\nThe sample for the survey is selected to represent the U.S. population of all ages. To produce reliable statistics, NHANES over-samples persons 60 and older, African Americans, and Hispanics.\n\nSince the United States has experienced dramatic growth in the number of older people during this century, the aging population has major implications for health care needs, public policy, and research priorities. NCHS is working with public health agencies to increase the knowledge of the health status of older Americans. NHANES has a primary role in this endeavor.\n\nAll participants visit the physician. Dietary interviews and body measurements are included for everyone. All but the very young have a blood sample taken and will have a dental screening. Depending upon the age of the participant, the rest of the examination includes tests and procedures to assess the various aspects of health listed above. In general, the older the individual, the more extensive the examination.\nChatGPT gave back to me the following:\n{\n  \"surveyDetails\": {\n    \"purpose\": \"Data collection on the prevalence of chronic conditions in the population\",\n    \"strength\": \"Information on undiagnosed and diagnosed chronic conditions\",\n    \"program\": \"NHANES (National Health and Nutrition Examination Survey)\"\n  },\n  \"riskFactors\": {\n    \"categories\": [\n      \"Smoking\",\n      \"Alcohol consumption\",\n      \"Sexual practices\",\n      \"Drug use\",\n      \"Physical fitness and activity\",\n      \"Weight\",\n      \"Dietary intake\",\n      \"Reproductive health (e.g., oral contraceptives, breastfeeding)\"\n    ]\n  },\n  \"healthTopics\": {\n    \"toStudy\": [\n      \"Anemia\",\n      \"Cardiovascular disease\",\n      \"Diabetes\",\n      \"Environmental exposures\",\n      \"Eye diseases\",\n      \"Hearing loss\",\n      \"Infectious diseases\",\n      \"Kidney disease\",\n      \"Nutrition\",\n      \"Obesity\",\n      \"Oral health\",\n      \"Osteoporosis\",\n      \"Physical fitness and physical functioning\",\n      \"Reproductive history and sexual behavior\",\n      \"Respiratory disease (asthma, chronic bronchitis, emphysema)\",\n      \"Sexually transmitted diseases\",\n      \"Vision\"\n    ]\n  },\n  \"sampleSelection\": {\n    \"representativeOf\": \"U.S. population of all ages\",\n    \"oversampling\": [\n      \"Persons 60 and older\",\n      \"African Americans\",\n      \"Hispanics\"\n    ]\n  },\n  \"implications\": {\n    \"agingPopulation\": {\n      \"impact\": \"Major implications for health care needs, public policy, and research priorities\",\n      \"focus\": \"NCHS (National Center for Health Statistics) working to increase knowledge of health status of older Americans\",\n      \"role\": \"NHANES has a primary role in this endeavor\"\n    }\n  },\n  \"participantDetails\": {\n    \"commonActivities\": [\n      \"Visit to physician\",\n      \"Dietary interviews\",\n      \"Body measurements\"\n    ],\n    \"commonTests\": [\n      \"Blood sample (for all but the very young)\",\n      \"Dental screening\"\n    ],\n    \"ageDependentTests\": \"Tests and procedures to assess various aspects of health, with the extent increasing with age\"\n  }\n}"
  },
  {
    "objectID": "2023-11-27-CUNY-json-data/talk.html#conclusion",
    "href": "2023-11-27-CUNY-json-data/talk.html#conclusion",
    "title": "Javascript Object Notation (JSON)",
    "section": "Conclusion",
    "text": "Conclusion\nIn this lesson, we learned about how the web works, how computers represent the data when it is transmitted over the web, how to parse the data into a format that can be used by a computer, how to extract the information that you want from the data, how to use the extracted information in your own application, and how to automate the process of extracting the information."
  },
  {
    "objectID": "2023-11-27-CUNY-json-data/talk.html#references",
    "href": "2023-11-27-CUNY-json-data/talk.html#references",
    "title": "Javascript Object Notation (JSON)",
    "section": "References",
    "text": "References\n\nhttps://cran.r-project.org/web/packages/jsonlite/vignettes/json-aaquickstart.html"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#outline",
    "href": "2024-09-20-ml-intro/index.html#outline",
    "title": "Introduction to Machine Learning",
    "section": "Outline",
    "text": "Outline\n\nRelationship between AI and ML\nTypes of Machine Learning\nA little about data\nSupervised Learning\nUnsupervised Learning"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#an-ontology-of-ai",
    "href": "2024-09-20-ml-intro/index.html#an-ontology-of-ai",
    "title": "Introduction to Machine Learning",
    "section": "An Ontology of AI",
    "text": "An Ontology of AI"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#what-is-machine-learning",
    "href": "2024-09-20-ml-intro/index.html#what-is-machine-learning",
    "title": "Introduction to Machine Learning",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\nThe study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning systems give the computer the ability to learn without being explicitly programmed rules."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#what-is-deep-learning",
    "href": "2024-09-20-ml-intro/index.html#what-is-deep-learning",
    "title": "Introduction to Machine Learning",
    "section": "What is Deep Learning?",
    "text": "What is Deep Learning?\nMachine learning algorithms that are inspired by the structure and function of the brain. Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is often unstructured (i.e., text or images)."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#ai-vs.-ml-vs.-deep-learning",
    "href": "2024-09-20-ml-intro/index.html#ai-vs.-ml-vs.-deep-learning",
    "title": "Introduction to Machine Learning",
    "section": "AI vs. ML vs. Deep Learning",
    "text": "AI vs. ML vs. Deep Learning\n\n\nArtificialIntelligence\n\n\nMachineLearning\n\n\nDeepLearning"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#ai-vs.-ml-vs.-deep-learning-1",
    "href": "2024-09-20-ml-intro/index.html#ai-vs.-ml-vs.-deep-learning-1",
    "title": "Introduction to Machine Learning",
    "section": "AI vs. ML vs. Deep Learning",
    "text": "AI vs. ML vs. Deep Learning\n\n\nArtificialIntelligence\n\n\nMachineLearning\n\n\nDeepLearning"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#an-ontology-of-data",
    "href": "2024-09-20-ml-intro/index.html#an-ontology-of-data",
    "title": "Introduction to Machine Learning",
    "section": "An ontology of Data",
    "text": "An ontology of Data\n\n\n\n\nOne way to think about different classes of data."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#structured-data-vs-unstructured-data",
    "href": "2024-09-20-ml-intro/index.html#structured-data-vs-unstructured-data",
    "title": "Introduction to Machine Learning",
    "section": "Structured Data vs Unstructured Data",
    "text": "Structured Data vs Unstructured Data\n\n\n\n\n\n\n\n\n\nStructured data\nUnstructured data\n\n\n\n\nWhat is it?\nData that fits in a predefined data model or schema.\nData without an underlying model to discern attributes.\n\n\nBasic example\nAn Excel table.\nA collection of video files.\n\n\nBest for\nA set of predefined observations or characteristics (columns) on a collection of things (rows)\nAn associated collection of data, objects, or files where the attributes change or are unknown.\n\n\nCommon formats\nCSV, TSV, Excel, SQL databases.\nImages, audio, video, text."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#tabular-data",
    "href": "2024-09-20-ml-intro/index.html#tabular-data",
    "title": "Introduction to Machine Learning",
    "section": "Tabular Data",
    "text": "Tabular Data\n\nRows and columns\nEach column has a specific data type\nEach row represents an observation on a subject (e.g., patient, sample)\n\nTerminology:\n\nFeature: A column in the dataset\nTarget: The variable you are trying to predict\nObservation: A row in the dataset\nDimension: The number of features in the dataset (sometimes represented by \\(p\\))\nSample: A single row in the dataset (usually represented by \\(n\\))"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#classes-of-machine-learning",
    "href": "2024-09-20-ml-intro/index.html#classes-of-machine-learning",
    "title": "Introduction to Machine Learning",
    "section": "Classes of Machine Learning",
    "text": "Classes of Machine Learning\n\nBroad classes of machine learning."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#types-of-machine-learning",
    "href": "2024-09-20-ml-intro/index.html#types-of-machine-learning",
    "title": "Introduction to Machine Learning",
    "section": "Types of Machine Learning",
    "text": "Types of Machine Learning\n\nSupervised Learning\n\nClassification\nRegression\n\nUnsupervised Learning\n\nClustering\nDimensionality Reduction\n\nReinforcement Learning"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#reinforecement-learning",
    "href": "2024-09-20-ml-intro/index.html#reinforecement-learning",
    "title": "Introduction to Machine Learning",
    "section": "Reinforecement Learning",
    "text": "Reinforecement Learning\n\nLearning through interaction: Unlike supervised learning where you have labeled data, RL agents learn by interacting with an environment.\nDelayed rewards: The agent doesn’t receive immediate feedback about the optimal action, but rather must learn which actions lead to better cumulative rewards over time.\nExploration vs. exploitation: The agent must balance exploring new actions versus exploiting known good actions.\nSequential decision making: RL deals with sequences of decisions rather than one-time predictions.\n\n\nExamples\n\n\n\nGame playing (e.g., AlphaGo, OpenAI Five)\nRobotics control\n\n\n\nAutonomous driving\nTrading strategies"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#a-map-of-machine-learning-approaches",
    "href": "2024-09-20-ml-intro/index.html#a-map-of-machine-learning-approaches",
    "title": "Introduction to Machine Learning",
    "section": "A map of machine learning approaches",
    "text": "A map of machine learning approaches\n\n\nhttps://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#supervised-learning-1",
    "href": "2024-09-20-ml-intro/index.html#supervised-learning-1",
    "title": "Introduction to Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\n\nGiven a dataset of input-output pairs: \\(\\{(x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)\\}\\)\nLearn a function \\(f\\) with parameters \\(\\theta\\) that maps inputs \\(x\\) to outputs \\(y\\) \\[y = f(x; \\theta) + \\epsilon\\]\nObjective: Choose parameters \\(\\theta\\) to minimize the prediction error \\(\\epsilon\\)"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#supervised-learning-2",
    "href": "2024-09-20-ml-intro/index.html#supervised-learning-2",
    "title": "Introduction to Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\nWhen \\(y\\) is a continuous variable (e.g., house prices), it’s a regression problem.\nWhen \\(y\\) is a discrete variable (e.g., spam or not spam), it’s a classification problem.\n\nIt is not a concidence that the same terms are used in statistics! Many machine learning algorithms are based on statistical principles or are generalizations of statistical methods."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#classification",
    "href": "2024-09-20-ml-intro/index.html#classification",
    "title": "Introduction to Machine Learning",
    "section": "Classification",
    "text": "Classification"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#regression",
    "href": "2024-09-20-ml-intro/index.html#regression",
    "title": "Introduction to Machine Learning",
    "section": "Regression",
    "text": "Regression\n\nNot all regression is linear…."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#classification-example",
    "href": "2024-09-20-ml-intro/index.html#classification-example",
    "title": "Introduction to Machine Learning",
    "section": "Classification Example",
    "text": "Classification Example\n\nThe classic iris"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#classification-example-1",
    "href": "2024-09-20-ml-intro/index.html#classification-example-1",
    "title": "Introduction to Machine Learning",
    "section": "Classification Example",
    "text": "Classification Example\n\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n6.2\n2.8\n4.8\n1.8\nvirginica\n\n\n4.8\n3.4\n1.6\n0.2\nsetosa\n\n\n5.0\n3.4\n1.5\n0.2\nsetosa\n\n\n5.9\n3.2\n4.8\n1.8\nversicolor\n\n\n5.8\n4.0\n1.2\n0.2\nsetosa\n\n\n5.8\n2.7\n3.9\n1.2\nversicolor\n\n\n6.7\n3.1\n4.7\n1.5\nversicolor\n\n\n5.6\n2.8\n4.9\n2.0\nvirginica\n\n\n6.3\n2.8\n5.1\n1.5\nvirginica\n\n\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.5\n2.4\n3.8\n1.1\nversicolor\n\n\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n5.6\n3.0\n4.5\n1.5\nversicolor\n\n\n7.3\n2.9\n6.3\n1.8\nvirginica\n\n\n6.1\n3.0\n4.9\n1.8\nvirginica\n\n\n4.3\n3.0\n1.1\n0.1\nsetosa\n\n\n6.4\n3.2\n5.3\n2.3\nvirginica\n\n\n4.8\n3.0\n1.4\n0.3\nsetosa\n\n\n6.1\n2.9\n4.7\n1.4\nversicolor"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#classification-example-2",
    "href": "2024-09-20-ml-intro/index.html#classification-example-2",
    "title": "Introduction to Machine Learning",
    "section": "Classification Example",
    "text": "Classification Example"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#training-and-testing",
    "href": "2024-09-20-ml-intro/index.html#training-and-testing",
    "title": "Introduction to Machine Learning",
    "section": "Training and Testing",
    "text": "Training and Testing\n\n\nTraining Data: Used to teach the model. It consists of input-output pairs for a supervised learning task.\nTesting Data: Used to evaluate the model’s performance. It should be separate from the training data, but come from the same distribution or population.\nValidation Data: Used for tuning hyperparameters. Hyperparameters are settings that control the learning process (e.g., k in k-NN, learning rate in neural networks)."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#generalizability",
    "href": "2024-09-20-ml-intro/index.html#generalizability",
    "title": "Introduction to Machine Learning",
    "section": "Generalizability",
    "text": "Generalizability\n\nThe ability of a model to perform well on unseen data\n\nThis table shows the relationship between training error, testing error, and overfitting, good fit, and underfitting.\n\n\n\nTraining Error\nTesting Error\nModel Fit\n\n\n\n\nLow\nHigh\nOverfit\n\n\nLow\nLow\nGood Fit\n\n\nHigh\nHigh\nUnderfit (poor performance)"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#bias-and-variance",
    "href": "2024-09-20-ml-intro/index.html#bias-and-variance",
    "title": "Introduction to Machine Learning",
    "section": "Bias and Variance",
    "text": "Bias and Variance\n\nBias: Error from incorrect assumptions in the learning algorithm\nVariance: Error from sensitivity to small fluctuations in the training set\nBias-Variance Tradeoff: The conflict in trying to simultaneously minimize these two sources of error"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#classification-example-3",
    "href": "2024-09-20-ml-intro/index.html#classification-example-3",
    "title": "Introduction to Machine Learning",
    "section": "Classification Example",
    "text": "Classification Example"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#classification-example-4",
    "href": "2024-09-20-ml-intro/index.html#classification-example-4",
    "title": "Introduction to Machine Learning",
    "section": "Classification Example",
    "text": "Classification Example"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#classification-example-5",
    "href": "2024-09-20-ml-intro/index.html#classification-example-5",
    "title": "Introduction to Machine Learning",
    "section": "Classification Example",
    "text": "Classification Example"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#regression-example",
    "href": "2024-09-20-ml-intro/index.html#regression-example",
    "title": "Introduction to Machine Learning",
    "section": "Regression Example",
    "text": "Regression Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-49.071 -11.047  -0.692  12.970  41.897 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.72808    3.68575  -0.198    0.844    \nx            2.05022    0.06336  32.356   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18.29 on 98 degrees of freedom\nMultiple R-squared:  0.9144,    Adjusted R-squared:  0.9135 \nF-statistic:  1047 on 1 and 98 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#regression-example-1",
    "href": "2024-09-20-ml-intro/index.html#regression-example-1",
    "title": "Introduction to Machine Learning",
    "section": "Regression Example",
    "text": "Regression Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-98.143 -22.095  -1.385  25.940  83.795 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -1.4562     7.3715  -0.198    0.844    \nx             2.1004     0.1267  16.574   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 36.58 on 98 degrees of freedom\nMultiple R-squared:  0.7371,    Adjusted R-squared:  0.7344 \nF-statistic: 274.7 on 1 and 98 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#regression-example-2",
    "href": "2024-09-20-ml-intro/index.html#regression-example-2",
    "title": "Introduction to Machine Learning",
    "section": "Regression Example",
    "text": "Regression Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-171.749  -38.665   -2.423   45.395  146.641 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -2.5483    12.9001  -0.198    0.844    \nx             2.1758     0.2218   9.811 3.12e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 64.02 on 98 degrees of freedom\nMultiple R-squared:  0.4955,    Adjusted R-squared:  0.4904 \nF-statistic: 96.25 on 1 and 98 DF,  p-value: 3.116e-16"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#more-complex-regression-example",
    "href": "2024-09-20-ml-intro/index.html#more-complex-regression-example",
    "title": "Introduction to Machine Learning",
    "section": "More Complex Regression Example",
    "text": "More Complex Regression Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\nobese\n\n\n\n\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.924\nnot obese\n\n\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.552\nobese\n\n\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.462\nobese\n\n\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.471\nnot obese\n\n\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.855\nnot obese\n\n\n31\nfemale\n25.740\n0\nno\nsoutheast\n3756.622\nnot obese\n\n\n46\nfemale\n33.440\n1\nno\nsoutheast\n8240.590\nobese\n\n\n37\nfemale\n27.740\n3\nno\nnorthwest\n7281.506\nnot obese\n\n\n37\nmale\n29.830\n2\nno\nnortheast\n6406.411\nnot obese\n\n\n60\nfemale\n25.840\n0\nno\nnorthwest\n28923.137\nnot obese"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#more-complex-regression-example-1",
    "href": "2024-09-20-ml-intro/index.html#more-complex-regression-example-1",
    "title": "Introduction to Machine Learning",
    "section": "More Complex Regression Example",
    "text": "More Complex Regression Example\n\nWhat do you think about the relationship between age and insurance charges?"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#more-complex-regression-example-2",
    "href": "2024-09-20-ml-intro/index.html#more-complex-regression-example-2",
    "title": "Introduction to Machine Learning",
    "section": "More Complex Regression Example",
    "text": "More Complex Regression Example"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#more-complex-regression-example-3",
    "href": "2024-09-20-ml-intro/index.html#more-complex-regression-example-3",
    "title": "Introduction to Machine Learning",
    "section": "More Complex Regression Example",
    "text": "More Complex Regression Example\n\n\n\nCall:\nlm(formula = charges ~ age + smoker + sex + obese, data = insurance)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13821.5  -3647.0   -225.8   1491.3  26884.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -4051.16     542.42  -7.469 1.46e-13 ***\nage           261.73      11.82  22.149  &lt; 2e-16 ***\nsmokeryes   23861.89     410.79  58.087  &lt; 2e-16 ***\nsexmale      -114.30     331.89  -0.344    0.731    \nobeseobese   4234.44     332.58  12.732  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6044 on 1333 degrees of freedom\nMultiple R-squared:  0.7516,    Adjusted R-squared:  0.7509 \nF-statistic:  1008 on 4 and 1333 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#algorithms-for-supervised-learning",
    "href": "2024-09-20-ml-intro/index.html#algorithms-for-supervised-learning",
    "title": "Introduction to Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\n\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-24.5356  -5.5236  -0.3462   6.4850  20.9487 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.36404    1.84287  -0.198    0.844    \nx            2.02511    0.03168  63.920   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.145 on 98 degrees of freedom\nMultiple R-squared:  0.9766,    Adjusted R-squared:  0.9763 \nF-statistic:  4086 on 1 and 98 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#algorithms-for-supervised-learning-1",
    "href": "2024-09-20-ml-intro/index.html#algorithms-for-supervised-learning-1",
    "title": "Introduction to Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nAnscombe’s Quartet\nhttps://en.wikipedia.org/wiki/Anscombe%27s_quartet"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#algorithms-for-supervised-learning-2",
    "href": "2024-09-20-ml-intro/index.html#algorithms-for-supervised-learning-2",
    "title": "Introduction to Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nK-nearest neighbor (kNN) algorithm."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#algorithms-for-supervised-learning-3",
    "href": "2024-09-20-ml-intro/index.html#algorithms-for-supervised-learning-3",
    "title": "Introduction to Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nClassification and Regression Trees (CART)."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#algorithms-for-supervised-learning-4",
    "href": "2024-09-20-ml-intro/index.html#algorithms-for-supervised-learning-4",
    "title": "Introduction to Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nRandom Forests."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#algorithms-for-supervised-learning-5",
    "href": "2024-09-20-ml-intro/index.html#algorithms-for-supervised-learning-5",
    "title": "Introduction to Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nDeep learning."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#applying-supervised-learning-algorithms",
    "href": "2024-09-20-ml-intro/index.html#applying-supervised-learning-algorithms",
    "title": "Introduction to Machine Learning",
    "section": "Applying Supervised Learning Algorithms",
    "text": "Applying Supervised Learning Algorithms\n\nThe mlr3 ecosystem in R."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#key-concepts-in-supervised-learning",
    "href": "2024-09-20-ml-intro/index.html#key-concepts-in-supervised-learning",
    "title": "Introduction to Machine Learning",
    "section": "Key Concepts in Supervised Learning",
    "text": "Key Concepts in Supervised Learning\n\nFeature Engineering\nModel Selection\nHyperparameter Tuning\nEnsemble Methods\nCross-Validation\nEvaluation Metrics\n\n\nBriefly explain each concept: 1. Feature Engineering: Creating new features or transforming existing ones to improve model performance 2. Model Selection: Choosing the appropriate algorithm for your problem 3. Hyperparameter Tuning: Optimizing model parameters that are not learned from data 4. Ensemble Methods: Combining multiple models to improve performance 5. Cross-Validation: Technique for assessing how the model will generalize to an independent dataset 6. Evaluation Metrics: Different ways to measure model performance (accuracy, precision, recall, F1-score, ROC curve, etc.)"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#challenges-in-machine-learning",
    "href": "2024-09-20-ml-intro/index.html#challenges-in-machine-learning",
    "title": "Introduction to Machine Learning",
    "section": "Challenges in Machine Learning",
    "text": "Challenges in Machine Learning\n\nData Quality and Quantity\nInterpretability vs Performance\nEthical Considerations and Bias\nComputational Resources\nModel Deployment and Maintenance\n\n\nDiscuss each challenge: 1. The importance of good, representative data and the challenges of data collection and cleaning 2. The tradeoff between complex, high-performing models and simpler, more interpretable ones 3. The risk of perpetuating or amplifying societal biases through ML models 4. The need for significant computational power, especially for deep learning models 5. The challenges of deploying models in production environments and keeping them updated"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#clustering",
    "href": "2024-09-20-ml-intro/index.html#clustering",
    "title": "Introduction to Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nGene expression measurements."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#classes-of-unsupervised-learning-algorithms",
    "href": "2024-09-20-ml-intro/index.html#classes-of-unsupervised-learning-algorithms",
    "title": "Introduction to Machine Learning",
    "section": "Classes of unsupervised learning algorithms",
    "text": "Classes of unsupervised learning algorithms\n\n\n\n\n\nClustering.\n\n\n\n\n\n\nDimensionality reduction."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#clustering-1",
    "href": "2024-09-20-ml-intro/index.html#clustering-1",
    "title": "Introduction to Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nThinking about similarities and differences"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#clustering-2",
    "href": "2024-09-20-ml-intro/index.html#clustering-2",
    "title": "Introduction to Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#clustering-3",
    "href": "2024-09-20-ml-intro/index.html#clustering-3",
    "title": "Introduction to Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#clustering-4",
    "href": "2024-09-20-ml-intro/index.html#clustering-4",
    "title": "Introduction to Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#dimensionality-reduction",
    "href": "2024-09-20-ml-intro/index.html#dimensionality-reduction",
    "title": "Introduction to Machine Learning",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\n\nSchematic PCA."
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#dimensionality-reduction-1",
    "href": "2024-09-20-ml-intro/index.html#dimensionality-reduction-1",
    "title": "Introduction to Machine Learning",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\n\nUsing dimensionality reduction to explore 22,000 dimensions of gene expression data on 280 samples.\nhttps://seandavi.github.io/ITR/geoquery_mds.html"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#future-directions-in-machine-learning",
    "href": "2024-09-20-ml-intro/index.html#future-directions-in-machine-learning",
    "title": "Introduction to Machine Learning",
    "section": "Future Directions in Machine Learning",
    "text": "Future Directions in Machine Learning\n\nAutoML: Automating the ML pipeline\nFederated Learning: Training models on decentralized data\nExplainable AI: Making black-box models more interpretable\nQuantum Machine Learning: Leveraging quantum computing for ML\nContinual Learning: Adapting to new data without forgetting old patterns"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#conclusion",
    "href": "2024-09-20-ml-intro/index.html#conclusion",
    "title": "Introduction to Machine Learning",
    "section": "Conclusion",
    "text": "Conclusion\n\nSupervised learning: Predicting outcomes based on labeled data\n\nClassification: Assigning labels to data\nRegression: Predicting continuous values\n\nUnsupervised learning: Finding patterns in unlabeled data\n\nClustering: Grouping similar data points\nDimensionality reduction: Simplifying complex data by reducing dimensions\n\nReinforcement learning: Learning through interaction with an environment"
  },
  {
    "objectID": "2024-09-20-ml-intro/index.html#resources",
    "href": "2024-09-20-ml-intro/index.html#resources",
    "title": "Introduction to Machine Learning",
    "section": "Resources",
    "text": "Resources\n\nRecent reviews\n\nMachine Learning in Genomic Medicine: A Review of Computational Problems and Data Sets\nOpportunities And Obstacles For Deep Learning In Biology And Medicine\n\nHands-on Tutorials\n\nhttps://seandavi.github.io/RBiocBook\nMany online courses and tutorials\n\nBlogs and online materials\n\nhttps://blog.recast.ai/machine-learning-algorithms/\nhttps://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A\nhttps://www.youtube.com/c/joshstarmer\n\nMachine Learning in R\n\nhttps://www.datacamp.com/community/tutorials/machine-learning-in-r\nhttps://daviddalpiaz.github.io/r4sl/"
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#introduction",
    "href": "2024-09-19-ai-history/index.html#introduction",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Introduction",
    "text": "Introduction\n\nArtificial Intelligence (AI) and Machine Learning (ML) have a rich history\nFrom early concepts to modern applications\nThis presentation covers key milestones and breakthroughs"
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#early-beginnings-1940s-1950s",
    "href": "2024-09-19-ai-history/index.html#early-beginnings-1940s-1950s",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Early Beginnings (1940s-1950s)",
    "text": "Early Beginnings (1940s-1950s)\n\n\n\n1936: Turing and the Computable Numbers (Turing 1936)\n1943: McCulloch and Pitts create a computational model for neural networks\n1950: Alan Turing proposes the Turing Test (Turing 1950) and Paper\n1956: Dartmouth Conference coins the term “Artificial Intelligence”"
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#i-robot-by-isaac-asimov",
    "href": "2024-09-19-ai-history/index.html#i-robot-by-isaac-asimov",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "“I, Robot” by Isaac Asimov",
    "text": "“I, Robot” by Isaac Asimov\n\n\n\nPublished in 1950 by Gnome Press\nCollection of nine science fiction short stories\nOriginally appeared in super-science fiction magazines (1940-1950)\nIntroduced the concept of positronic robots and the Three Laws of Robotics\n\n\n\n\nAsimov (1950)\n\nAsimov’s work laid the foundation for ethical considerations in AI development."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#the-three-laws-of-robotics",
    "href": "2024-09-19-ai-history/index.html#the-three-laws-of-robotics",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "The Three Laws of Robotics",
    "text": "The Three Laws of Robotics\n\nA robot may not injure a human being or, through inaction, allow a human being to come to harm.\nA robot must obey the orders given it by human beings except where such orders would conflict with the First Law.\nA robot must protect its own existence as long as such protection does not conflict with the First or Second Laws.\n\n\nAsimov later added the Zeroth Law that superseded the others:\n\nA robot may not harm humanity, or, by inaction, allow humanity to come to harm.\n\n\n\nThese laws have become a cornerstone in discussions about AI ethics and safety."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#i-robots-influence-on-modern-ai",
    "href": "2024-09-19-ai-history/index.html#i-robots-influence-on-modern-ai",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "“I, Robot”’s Influence on Modern AI",
    "text": "“I, Robot”’s Influence on Modern AI\n\nSparked discussions on machine ethics and AI safety\nInfluenced researchers to consider ethical implications of AI development\nConcept of “friendly AI” draws parallels to Asimov’s laws\nChallenges presented in stories mirror real-world AI alignment problems\n\n\nWhile not directly implementable, Asimov’s laws have shaped thinking about AI governance and ethics in the field."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#the-turing-test",
    "href": "2024-09-19-ai-history/index.html#the-turing-test",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "1950: The Turing Test",
    "text": "1950: The Turing Test\n\nWho’s the real human?"
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#the-golden-years-1956-1974",
    "href": "2024-09-19-ai-history/index.html#the-golden-years-1956-1974",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "The Golden Years (1956-1974)",
    "text": "The Golden Years (1956-1974)\n\nDevelopment of early AI programs\n1957: Frank Rosenblatt develops the Perceptron\n1964: ELIZA, one of the first chatbots, is created by Joseph Weizenbaum"
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#eliza-one-of-the-first-chatbots",
    "href": "2024-09-19-ai-history/index.html#eliza-one-of-the-first-chatbots",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "1964: ELIZA, one of the first chatbots",
    "text": "1964: ELIZA, one of the first chatbots\n\n\n\n\n\n\n\n\nAlthough ELIZA was limited in terms of actual understanding, it marked an important milestone in the development of AI and human-computer interaction, showing how conversation-based interfaces could influence the perception of intelligence.\n\n\nELIZA was one of the earliest chatbots, developed in the mid-1960s by Joseph Weizenbaum, a computer scientist at MIT. The program was designed to simulate a conversation between a human and a machine, and it did so by using pattern matching and substitution methodology, a simple but effective form of natural language processing.\nELIZA’s most famous script was called “DOCTOR,” which mimicked a Rogerian psychotherapist. In this role, ELIZA would take users’ input and reflect their statements back to them in a way that encouraged further conversation. For example, if a user said, “I’m feeling sad today,” ELIZA might respond with, “Why do you think you’re feeling sad today?”\nWhile ELIZA’s responses were largely superficial, many users were surprised at how human-like they seemed. Weizenbaum created ELIZA to demonstrate how easily people could attribute human-like understanding to a machine, even when its responses were formulaic. He was struck by how quickly people became emotionally attached to the program, despite knowing it was not genuinely intelligent.\nAlthough ELIZA was limited in terms of actual understanding, it marked an important milestone in the development of AI and human-computer interaction, showing how conversation-based interfaces could influence the perception of intelligence."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#what-is-an-expert-system",
    "href": "2024-09-19-ai-history/index.html#what-is-an-expert-system",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "What is an Expert System?",
    "text": "What is an Expert System?\n\nDefinition: Computer program that emulates decision-making ability of a human expert\nKey Components:\n\nKnowledge Base: Contains domain-specific information and rules\nInference Engine: Applies rules to the knowledge to derive new information\nUser Interface: Allows non-expert users to interact with the system\n\nCharacteristics:\n\nSolves complex problems by reasoning through bodies of knowledge\nSeparates domain knowledge from the reasoning mechanism\nCan explain its decisions and reasoning"
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#what-is-an-expert-system-1",
    "href": "2024-09-19-ai-history/index.html#what-is-an-expert-system-1",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "What is an Expert System?",
    "text": "What is an Expert System?\n\nApplications:\n\nMedical diagnosis (e.g., MYCIN)\nFinancial planning\nManufacturing process control\nScientific analysis\n\nAdvantages:\n\nConsistent and accurate decisions\nPreservation of expert knowledge\nAbility to handle complex scenarios\n\nLimitations:\n\nLimited to specific domains (narrow AI)\nDifficulty in capturing tacit knowledge\nMay struggle with unusual or unprecedented situations"
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#example-expert-system-mycin",
    "href": "2024-09-19-ai-history/index.html#example-expert-system-mycin",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Example Expert system: MYCIN",
    "text": "Example Expert system: MYCIN\n\nDeveloped in the early 1970s at Stanford University\nOne of the first rule-based expert systems in medicine\nPurpose: Assist physicians in diagnosing and treating bacterial infections\nFocused on bloodstream infections (bacteremia and meningitis)\nNamed after antibiotics (many of which end in “-mycin”)"
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#mycin-key-features-and-functionality",
    "href": "2024-09-19-ai-history/index.html#mycin-key-features-and-functionality",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "MYCIN: Key Features and Functionality",
    "text": "MYCIN: Key Features and Functionality\n\nRule-based system with approximately 600 rules\nUsed backward chaining inference engine\nIncorporated certainty factors to handle uncertainty\nAsked users a series of yes/no questions about symptoms and test results\nProvided diagnosis recommendations and suggested antibiotic treatments\nExplained its reasoning process to user"
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#mycin-impact-and-legacy",
    "href": "2024-09-19-ai-history/index.html#mycin-impact-and-legacy",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "MYCIN: Impact and Legacy",
    "text": "MYCIN: Impact and Legacy\n\nNever used in clinical practice due to ethical and legal concerns\nAchieved performance comparable to human experts in its domain\nPioneered several important concepts in AI and expert systems:\n\nSeparation of knowledge base from inference engine\nExplanation of reasoning\nHandling of uncertainty\n\nInfluenced development of subsequent expert systems and clinical decision support tools\nDemonstrated potential of AI in healthcare, paving way for modern medical AI applications"
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#increased-computational-power",
    "href": "2024-09-19-ai-history/index.html#increased-computational-power",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Increased Computational Power",
    "text": "Increased Computational Power\n\nAdvancement:\n\nRapid growth of CPUs and the emergence of GPUs (Graphics Processing Units).\n\nImpact:\n\nEnabled the training of deeper neural networks essential for various AI tasks."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#big-data",
    "href": "2024-09-19-ai-history/index.html#big-data",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Big Data",
    "text": "Big Data\n\nAdvancement:\n\nExplosion of digital data from the internet, social media, and sensors.\n\nImpact:\n\nFacilitated the development of accurate models as ML algorithms require substantial data to learn effectively."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#open-source-frameworks-and-libraries",
    "href": "2024-09-19-ai-history/index.html#open-source-frameworks-and-libraries",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Open Source Frameworks and Libraries",
    "text": "Open Source Frameworks and Libraries\n\nAdvancement:\n\nEmergence of libraries like TensorFlow (2015), Keras (2015), and Scikit-learn (2007).\n\nImpact:\n\nLowered the barrier for AI development, allowing more practitioners to innovate in the field."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#advances-in-algorithms",
    "href": "2024-09-19-ai-history/index.html#advances-in-algorithms",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Advances in Algorithms",
    "text": "Advances in Algorithms\n\nAdvancement:\n\nResearch in new algorithms, such as support vector machines and deep learning architectures.\n\nImpact:\n\nImproved AI performance across applications, particularly in image and speech recognition."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#cloud-computing",
    "href": "2024-09-19-ai-history/index.html#cloud-computing",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Cloud Computing",
    "text": "Cloud Computing\n\nAdvancement:\n\nRise of cloud computing platforms (e.g., AWS, Google Cloud, Microsoft Azure).\n\nImpact:\n\nProvided scalable resources for storage and computation, enabling extensive ML experimentation."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#collaborative-research-and-knowledge-sharing",
    "href": "2024-09-19-ai-history/index.html#collaborative-research-and-knowledge-sharing",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Collaborative Research and Knowledge Sharing",
    "text": "Collaborative Research and Knowledge Sharing\n\nAdvancement:\n\nIncreased collaboration and sharing of findings through conferences and online platforms.\n\nImpact:\n\nAccelerated innovation in AI and ML as researchers built upon each other’s work."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#investment-and-interest-from-industry",
    "href": "2024-09-19-ai-history/index.html#investment-and-interest-from-industry",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Investment and Interest from Industry",
    "text": "Investment and Interest from Industry\n\nAdvancement:\n\nGrowing interest and investment from tech giants and startups in AI technologies.\n\nImpact:\n\nLed to the development of practical applications and commercial products, driving further research."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#deep-learning-resurgence-2006",
    "href": "2024-09-19-ai-history/index.html#deep-learning-resurgence-2006",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Deep Learning Resurgence (2006)",
    "text": "Deep Learning Resurgence (2006)\n\nMilestone: Geoffrey Hinton and team introduced “deep belief networks.”\nImpact: Marked the resurgence of deep learning and laid the foundation for modern AI applications, especially in image and speech recognition."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#alexnet-wins-imagenet-competition-2012",
    "href": "2024-09-19-ai-history/index.html#alexnet-wins-imagenet-competition-2012",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "AlexNet Wins ImageNet Competition (2012)",
    "text": "AlexNet Wins ImageNet Competition (2012)\n\nMilestone: Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton’s deep neural network (AlexNet) won the ImageNet competition.\nImpact: Showcased the power of convolutional neural networks (CNNs) and triggered widespread adoption in computer vision tasks."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#ibm-watson-wins-jeopardy-2011",
    "href": "2024-09-19-ai-history/index.html#ibm-watson-wins-jeopardy-2011",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "IBM Watson Wins Jeopardy! (2011)",
    "text": "IBM Watson Wins Jeopardy! (2011)\n\nMilestone: IBM Watson defeated champions Ken Jennings and Brad Rutter on Jeopardy!.\nImpact: Demonstrated AI’s ability to process and understand natural language, leading to applications in healthcare, finance, and customer service."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#md-anderson-sets-watson-aside-2017-2018",
    "href": "2024-09-19-ai-history/index.html#md-anderson-sets-watson-aside-2017-2018",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "MD Anderson sets Watson aside (2017-2018)",
    "text": "MD Anderson sets Watson aside (2017-2018)\n\nSee Herper (n.d.)"
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#generative-adversarial-networks-gans-2014",
    "href": "2024-09-19-ai-history/index.html#generative-adversarial-networks-gans-2014",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Generative Adversarial Networks (GANs) (2014)",
    "text": "Generative Adversarial Networks (GANs) (2014)\n\nMilestone: Ian Goodfellow introduced GANs, a model where two neural networks compete to generate realistic data.\nImpact: Revolutionized image generation and unsupervised learning, powering innovations like deepfakes and AI-generated art."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#alphago-defeats-world-champion-2016",
    "href": "2024-09-19-ai-history/index.html#alphago-defeats-world-champion-2016",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "AlphaGo Defeats World Champion (2016)",
    "text": "AlphaGo Defeats World Champion (2016)\n\nMilestone: Google DeepMind’s AlphaGo defeated Go champion Lee Sedol.\nImpact: Showcased the capability of reinforcement learning and deep neural networks in mastering complex strategic games."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#transformer-architecture-2017",
    "href": "2024-09-19-ai-history/index.html#transformer-architecture-2017",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Transformer Architecture (2017)",
    "text": "Transformer Architecture (2017)\n\nMilestone: Vaswani et al. introduced the Transformer model, revolutionizing natural language processing.\nImpact: Laid the groundwork for state-of-the-art NLP models like BERT and GPT, transforming language understanding and generation."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#ai-and-ml-in-social-media-2010s",
    "href": "2024-09-19-ai-history/index.html#ai-and-ml-in-social-media-2010s",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "AI and ML in Social Media (2010s)",
    "text": "AI and ML in Social Media (2010s)\n\nMilestone: Social media platforms adopted AI for content recommendation and moderation.\nImpact: Enhanced user engagement and experience, but also raised concerns about echo chambers, misinformation, and algorithmic bias."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#alphafold-solves-protein-folding-2020",
    "href": "2024-09-19-ai-history/index.html#alphafold-solves-protein-folding-2020",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "AlphaFold Solves Protein Folding (2020)",
    "text": "AlphaFold Solves Protein Folding (2020)\n\nMilestone: DeepMind’s AlphaFold achieved breakthrough accuracy in predicting protein structures.\nImpact: Solved a 50-year-old challenge in biology, opening new doors in drug discovery and molecular biology."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#gpt-4-and-large-language-models-2023",
    "href": "2024-09-19-ai-history/index.html#gpt-4-and-large-language-models-2023",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "GPT-4 and Large Language Models (2023)",
    "text": "GPT-4 and Large Language Models (2023)\n\nMilestone: OpenAI’s GPT-4 showcased the potential of large-scale language models for complex, nuanced language understanding.\nImpact: Accelerated the development of AI-driven content creation and enhanced human-computer interaction."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#future-directions",
    "href": "2024-09-19-ai-history/index.html#future-directions",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Future Directions",
    "text": "Future Directions\n\nArtificial General Intelligence (AGI) research\nQuantum computing and AI\nNeuromorphic computing\nHuman-AI collaboration\n\nFor deeper dive into the history, see (Norman 2024)."
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#challenges-and-opportunities",
    "href": "2024-09-19-ai-history/index.html#challenges-and-opportunities",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Challenges and Opportunities",
    "text": "Challenges and Opportunities\n\nEthical AI development\nAI governance and regulation\nAddressing AI bias and fairness\nBalancing innovation with responsible development"
  },
  {
    "objectID": "2024-09-19-ai-history/index.html#references",
    "href": "2024-09-19-ai-history/index.html#references",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "References",
    "text": "References\n\n\n\n\nAsimov, Isaac. 1950. I, Robot. Bantam hardcover ed. (2). New York: Bantam Books.\n\n\nHerper, Matthew. n.d. “MD Anderson Benches IBM Watson In Setback For Artificial Intelligence In Medicine.” Forbes. Accessed October 2, 2024. https://www.forbes.com/sites/matthewherper/2017/02/19/md-anderson-benches-ibm-watson-in-setback-for-artificial-intelligence-in-medicine/.\n\n\nNorman, Jeremy. 2024. “History of Information.” https://www.historyofinformation.com/?cat=71.\n\n\nTuring, Alan. 1936. “On Computable Numbers, with an Application to the Entscheidungsproblem.” https://www.abelard.org/turpap2/tp2-ie.asp.\n\n\n———. 1950. “Computing Machinery and Intelligence.” Mind 59 (October): 433–60. https://doi.org/10.1093/mind/lix.236.433."
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#section",
    "href": "2024-10-23-ai-in-medical-education/index.html#section",
    "title": "AI in Medical Education",
    "section": "",
    "text": "“Maybe once every few decades a true revolution occurs in the way we teach medical students and what we expect them to be able to do when they become doctors. This is one of those times.”\n\n\n– Bernard Chang, MMSc ’05, HMS dean for medical education, Speaking about ChatGPT and Generative AI in Medical Education"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#what-we-will-not-cover-today",
    "href": "2024-10-23-ai-in-medical-education/index.html#what-we-will-not-cover-today",
    "title": "AI in Medical Education",
    "section": "What we will not cover today",
    "text": "What we will not cover today\n\nPersonal use of AI in medical education\nMany, many examples of AI in medical education"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#the-academic-medical-center-view",
    "href": "2024-10-23-ai-in-medical-education/index.html#the-academic-medical-center-view",
    "title": "AI in Medical Education",
    "section": "The academic medical center view",
    "text": "The academic medical center view\n\n\nhttps://seandavi.github.io/campus-llm-kb/framework.html"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#hypothetical-application-of-ai-in-education",
    "href": "2024-10-23-ai-in-medical-education/index.html#hypothetical-application-of-ai-in-education",
    "title": "AI in Medical Education",
    "section": "Hypothetical application of AI in education",
    "text": "Hypothetical application of AI in education\nYou are on the faculty of a medical school that has proposed to use ChatGPT to help draft letters of recommendation for medical school residency programs for its students.\n\nWhat are your thoughts?\nWhat are some specific concerns and recommendations that you would recommend to faculty leaders?"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#what-do-llms-know-about-medicine",
    "href": "2024-10-23-ai-in-medical-education/index.html#what-do-llms-know-about-medicine",
    "title": "AI in Medical Education",
    "section": "What do LLMs know about medicine?",
    "text": "What do LLMs know about medicine?\n\n\nhttps://arxiv.org/abs/2305.09617"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#what-do-llms-know-about-medicine-1",
    "href": "2024-10-23-ai-in-medical-education/index.html#what-do-llms-know-about-medicine-1",
    "title": "AI in Medical Education",
    "section": "What do LLMs know about medicine?",
    "text": "What do LLMs know about medicine?\n\n\nhttps://arxiv.org/abs/2305.09617"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#androgogy",
    "href": "2024-10-23-ai-in-medical-education/index.html#androgogy",
    "title": "AI in Medical Education",
    "section": "Androgogy",
    "text": "Androgogy\nIn addition to mutual respect, collaboration, support, mutual trust, and fun, additional key drivers of adult learning include\n\nBuilding on experience: Adults learn by relating new information to their own experiences and the experiences of others.\nLearning by doing: Adults need time for application exercises to practice new skills and knowledge. Different learning styles and rates: Adults learn in different ways and at different rates, so use a variety of instructional methods.\nKnowing why they need to learn: Adults need to know why they need to learn something.\nFeeling responsible for learning: Adults need to feel responsible for their learning.\nProblem focused: Adults want their training to be problem focused.\nIntrinsic motivation: Adults learn best when motivation comes intrinsically.\nFeedback and interaction: builds confidence which is a large component of learning success."
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#scoping-review-of-ai-in-medical-education",
    "href": "2024-10-23-ai-in-medical-education/index.html#scoping-review-of-ai-in-medical-education",
    "title": "AI in Medical Education",
    "section": "Scoping review of AI in medical education",
    "text": "Scoping review of AI in medical education\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#ai-for-admissions-and-selection",
    "href": "2024-10-23-ai-in-medical-education/index.html#ai-for-admissions-and-selection",
    "title": "AI in Medical Education",
    "section": "AI for Admissions and Selection",
    "text": "AI for Admissions and Selection\n\nAI can improve the admissions process by:\n\nPredicting student success (AUC of 0.925 in one study).\nAnalyzing application materials using sentiment analysis.\nAugmenting traditional holistic reviews.\n\nExample: ML models accurately ranked medical applicants based on retrospective data.\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#ai-augmented-instruction",
    "href": "2024-10-23-ai-in-medical-education/index.html#ai-augmented-instruction",
    "title": "AI in Medical Education",
    "section": "AI-Augmented Instruction",
    "text": "AI-Augmented Instruction\n\nAI for Personalized Education:\n\nAdaptive learning systems for tailoring content to individual student needs.\nExample: AI-driven tutoring systems providing real-time feedback during ultrasound training.\n\nAI-Enhanced Simulations:\n\nVirtual reality and AI-powered simulators used for surgery and clinical skills training.\nExample: Robotic surgery simulators to assess surgical competency.\n\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#ai-in-teaching-clinical-reasoning",
    "href": "2024-10-23-ai-in-medical-education/index.html#ai-in-teaching-clinical-reasoning",
    "title": "AI in Medical Education",
    "section": "AI in Teaching Clinical Reasoning",
    "text": "AI in Teaching Clinical Reasoning\n\nVirtual Patient Simulators (VPS):\n\nAI-driven platforms simulate real patient encounters.\nStudents interact with avatars or text interfaces, practicing hypothesis generation and clinical reasoning.\n\nIntelligent Tutoring Systems (ITS):\n\nProvides personalized feedback based on student inputs and performance.\nExample: NLP algorithms creating virtual patient case libraries.\n\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#ai-in-assessments",
    "href": "2024-10-23-ai-in-medical-education/index.html#ai-in-assessments",
    "title": "AI in Medical Education",
    "section": "AI in Assessments",
    "text": "AI in Assessments\n\nAI for Objective Structured Clinical Examinations (OSCE):\n\nAI enhances clinical skills assessments, reducing bias and logistical demands.\nAI can automate grading and real-time feedback during simulations.\n\nAI in Narrative Analysis:\n\nNLP for analyzing student reflections, faculty evaluations, and identifying bias in feedback.\nExample: AI assessed medical narratives for professionalism and clinical competency.\n\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#ai-generated-multiple-choice-questions",
    "href": "2024-10-23-ai-in-medical-education/index.html#ai-generated-multiple-choice-questions",
    "title": "AI in Medical Education",
    "section": "AI-Generated Multiple Choice Questions",
    "text": "AI-Generated Multiple Choice Questions\n\nAI can create and assess multiple-choice questions for exams.\nChatGPT has been widely tested, with mixed results in MCQ creation.\nExample: LLMs (Large Language Models) were tested on national licensure exams and performed comparably to humans in many cases.\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#ai-for-procedural-skills-and-automation",
    "href": "2024-10-23-ai-in-medical-education/index.html#ai-for-procedural-skills-and-automation",
    "title": "AI in Medical Education",
    "section": "AI for Procedural Skills and Automation",
    "text": "AI for Procedural Skills and Automation\n\nAI aids in documenting procedural and clinical experiences.\n\nNLP algorithms track clinical logs and case experiences, boosting accuracy and efficiency.\nExample: AI systems tracking neurology resident experiences, tripling the logged cases.\n\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#attitudes-toward-ai-in-medical-education",
    "href": "2024-10-23-ai-in-medical-education/index.html#attitudes-toward-ai-in-medical-education",
    "title": "AI in Medical Education",
    "section": "Attitudes Toward AI in Medical Education",
    "text": "Attitudes Toward AI in Medical Education\n\nMixed perceptions on AI’s role:\n\nMany students recognize AI’s benefits, such as enhanced clinical decision-making.\nConcerns about AI’s impact on doctor-patient relationships and potential over-reliance on technology.\n\nCalls for comprehensive AI curricula to prepare future physicians for AI integration.\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#ethical-considerations",
    "href": "2024-10-23-ai-in-medical-education/index.html#ethical-considerations",
    "title": "AI in Medical Education",
    "section": "Ethical Considerations",
    "text": "Ethical Considerations\n\nBias and equity: AI models trained on non-representative data may exacerbate healthcare disparities.\nTransparency: Students must understand the ethical implications of AI’s involvement in clinical decisions.\nAutomation Bias: Students must maintain critical thinking skills and not overly rely on AI outputs.\n\nExample: AI in admissions can help reduce bias in holistic reviews but also risks introducing new biases.\n\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#a-sampling-of-policies-from-various-institutions",
    "href": "2024-10-23-ai-in-medical-education/index.html#a-sampling-of-policies-from-various-institutions",
    "title": "AI in Medical Education",
    "section": "A sampling of policies from various institutions",
    "text": "A sampling of policies from various institutions\n\n\n\nCarnegie Mellon University Examples of AI use policies for educators\nUniversity of Iowa, Office of Teaching, Learning, and Technology\nSFCC Library Faculty Help\nCleveland State University Center for Faculty Excellence\nClassroom Policies Related to ChatGPT and Other AI Tools\n\n\n\nMontclair State University AI Course Policies and Assignment Guidelines\nInside HigherEd Opinion Piece on Generative AI Policy Making\nStanford\nUpdate Your Syllabus for ChatGPT\nRules for Tools (from Padagogische Hochschule Heidelberg)\n\n\n\nhttps://seandavi.github.io/campus-llm-kb/resources_education.html#educational-policy-statements-and-guidelines"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#thinking-about-academic-integrity",
    "href": "2024-10-23-ai-in-medical-education/index.html#thinking-about-academic-integrity",
    "title": "AI in Medical Education",
    "section": "Thinking about academic integrity",
    "text": "Thinking about academic integrity\n\nIs there such a thing as “ChatGPT-proofing” your assignments?\nThe better question to ask is, “why do students plagiarize?”\n\nThe student may feel like they don’t know what a successful submission is, fear failing, or simply think something that wasn’t written specifically for the class can pass muster.\n\nHow do we approach building our assignments so there is trust between the instructor and student?\n\nThe instructor trusts that students will approach the assignment with motivation and a desire to put their own voice into the work.\nThe student trusts that the work they’re doing is meaningful and worth any struggle or challenges they come across."
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#appeals-for-academic-integrity",
    "href": "2024-10-23-ai-in-medical-education/index.html#appeals-for-academic-integrity",
    "title": "AI in Medical Education",
    "section": "Appeals for academic integrity",
    "text": "Appeals for academic integrity\nMost institutions include a formal academic code of conduct. However, it is often helpful to remind students of the importance of academic integrity and the consequences of cheating. Here are some appeals that can be used to encourage students to maintain academic integrity."
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#academic-integrity-logical-appeal",
    "href": "2024-10-23-ai-in-medical-education/index.html#academic-integrity-logical-appeal",
    "title": "AI in Medical Education",
    "section": "Academic integrity: Logical appeal",
    "text": "Academic integrity: Logical appeal\nCheating diminishes the value of this credential/course/degree. There will very soon come a time when you will need the skills and knowledge being assessed in this course, and you don’t want to find yourself in a position in which your pre-requisite/credentialed knowledge is fraudulent.\n\nhttps://teaching.cornell.edu/teaching-resources/assessment-evaluation/promoting-academic-integrity-your-course"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#academic-integrity-emotional-moral-appeal",
    "href": "2024-10-23-ai-in-medical-education/index.html#academic-integrity-emotional-moral-appeal",
    "title": "AI in Medical Education",
    "section": "Academic integrity: Emotional (moral) appeal",
    "text": "Academic integrity: Emotional (moral) appeal\nCheating is a temptation, of course, but it’s your personal integrity on the line. We are [NAME OF INSTITUTION] (YOU are [NAME OF INSTUTION]), and we are called to do the right thing.\n\nhttps://teaching.cornell.edu/teaching-resources/assessment-evaluation/promoting-academic-integrity-your-course"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#academic-integrity-personal-appeal",
    "href": "2024-10-23-ai-in-medical-education/index.html#academic-integrity-personal-appeal",
    "title": "AI in Medical Education",
    "section": "Academic integrity: Personal appeal",
    "text": "Academic integrity: Personal appeal\nAs I have made every effort to continue our class’s sense of community and purpose, I’m asking you to make every effort to be honest and honorable in the demonstration of what you have learned in our class.\n\nhttps://teaching.cornell.edu/teaching-resources/assessment-evaluation/promoting-academic-integrity-your-course"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom",
    "href": "2024-10-23-ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom",
    "title": "AI in Medical Education",
    "section": "Policies on AI use in the classroom",
    "text": "Policies on AI use in the classroom\nContent-generating AI is NOT Allowed:\n\nUnder this category, the use of AI tools is strictly prohibited. These syllabi are clear that work produced by students must be entirely original, and the use of AI-generated content will be considered academic misconduct.\nStatements falling into this category emphasize the core value of academic originality and stress the importance of mastering subjects without undue reliance on technological shortcuts.\n\n\nhttps://academic.wlu.edu/2023/08/17/thinking-about-updating-your-syllabus-for-chatgpt/"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom-1",
    "href": "2024-10-23-ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom-1",
    "title": "AI in Medical Education",
    "section": "Policies on AI use in the classroom",
    "text": "Policies on AI use in the classroom\nContent-generating AI is Allowed with Appropriate Attribution:\n\nPolicies in this grouping permit the use of AI for certain tasks or specific assignments, provided it is properly attributed. Students must clearly identify any writing, text, or media generated by AI when submitting work. They are also responsible for the accuracy of any generated content.\nSyllabi in this group might specify, for instance, that if a student employs AI tools like ChatGPT to generate content, this fact must be clearly indicated in their submission. The emphasis is on transparency and understanding the origin of academic materials.\n\n\nhttps://academic.wlu.edu/2023/08/17/thinking-about-updating-your-syllabus-for-chatgpt/"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom-2",
    "href": "2024-10-23-ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom-2",
    "title": "AI in Medical Education",
    "section": "Policies on AI use in the classroom",
    "text": "Policies on AI use in the classroom\nContent-generating AI Use is Allowed in LIMITED Instances\n\nThis grouping offers a middle ground. While AI is not entirely banned, its use is curtailed to very specific instances or types of assignments.\nSyllabi in this category might allow AI tools for preliminary stages of research, brainstorming, or concept development, but not for final submissions. Here, AI is viewed as an assistant rather than a creator, helping students in the preparation and formulation, but not execution of their academic tasks.\n\n\nhttps://academic.wlu.edu/2023/08/17/thinking-about-updating-your-syllabus-for-chatgpt/"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom-3",
    "href": "2024-10-23-ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom-3",
    "title": "AI in Medical Education",
    "section": "Policies on AI use in the classroom",
    "text": "Policies on AI use in the classroom\nContent-generating AI Use is Encouraged Broadly\n\nThe most progressive of the groupings, these policies embrace AI as a significant component of a rapidly evolving tech landscape.\nThese syllabi might encourage students to explore AI’s capabilities, suggesting that they employ these tools in various assignments to understand their potential and limitations. However, they still emphasize the importance of integrity, ensuring students do not misuse AI, but rather incorporate it as part of a holistic learning experience.\n\n\nhttps://academic.wlu.edu/2023/08/17/thinking-about-updating-your-syllabus-for-chatgpt/"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#recognize-that-ai-in-medical-education-is-still-about-education",
    "href": "2024-10-23-ai-in-medical-education/index.html#recognize-that-ai-in-medical-education-is-still-about-education",
    "title": "AI in Medical Education",
    "section": "Recognize that AI in medical education is STILL about education",
    "text": "Recognize that AI in medical education is STILL about education\n\n\nhttps://www.chronicle.com/article/how-chatgpt-could-help-or-hurt-students-with-disabilities"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education",
    "href": "2024-10-23-ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education",
    "title": "AI in Medical Education",
    "section": "Tips for addressing ethical concerns of AI in medical education",
    "text": "Tips for addressing ethical concerns of AI in medical education\n\nThis article discusses the ethical challenges that arise with the integration of artificial intelligence (AI) in medical education. The authors present twelve practical tips to guide medical educators in addressing these ethical issues and ensuring the responsible use of AI in educational settings.\n\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC10993743/"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#ethical-framework-for-ai-in-medical-education",
    "href": "2024-10-23-ai-in-medical-education/index.html#ethical-framework-for-ai-in-medical-education",
    "title": "AI in Medical Education",
    "section": "Ethical framework for AI in medical education",
    "text": "Ethical framework for AI in medical education\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education-1",
    "href": "2024-10-23-ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education-1",
    "title": "AI in Medical Education",
    "section": "Tips for addressing ethical concerns of AI in medical education",
    "text": "Tips for addressing ethical concerns of AI in medical education\n\nEnsure transparency in AI development and deployment.\nAddress biases in AI algorithms to ensure fair educational representation.\nValidate AI-generated educational content for accuracy and credibility.\nPrioritize privacy with robust measures for protecting student and patient data.\n\n\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC10993743/"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education-2",
    "href": "2024-10-23-ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education-2",
    "title": "AI in Medical Education",
    "section": "Tips for addressing ethical concerns of AI in medical education",
    "text": "Tips for addressing ethical concerns of AI in medical education\n\nObtain informed consent from students and stakeholders for AI usage.\nFoster collaboration between AI experts, educators, and students.\nConduct faculty development programs on AI ethics.\nProvide student education on AI’s implications in medical education.\n\n\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC10993743/"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education-3",
    "href": "2024-10-23-ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education-3",
    "title": "AI in Medical Education",
    "section": "Tips for addressing ethical concerns of AI in medical education",
    "text": "Tips for addressing ethical concerns of AI in medical education\n\nEnsure ongoing maintenance of AI algorithms for performance and reliability.\nEstablish clear lines of accountability for AI systems.\nEnhance regulatory awareness of AI standards in healthcare and education.\nForm ethics committees or engage institutional review boards for ethical oversight of AI.\n\n\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC10993743/"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#contributed-resources",
    "href": "2024-10-23-ai-in-medical-education/index.html#contributed-resources",
    "title": "AI in Medical Education",
    "section": "Contributed resources",
    "text": "Contributed resources\n\nLarge Language Models for Education: A Survey and Outlook\nAI and the future of medical education\nAI and Medical Student Learninghttps://pmc.ncbi.nlm.nih.gov/articles/PMC10755136/\nResidency Applications in the Era of Generative Artificial Intelligence"
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#understanding-the-ai-ecosystem-at-your-institution",
    "href": "2024-10-23-ai-in-medical-education/index.html#understanding-the-ai-ecosystem-at-your-institution",
    "title": "AI in Medical Education",
    "section": "Understanding the AI ecosystem at your institution",
    "text": "Understanding the AI ecosystem at your institution\n\nFACETS framework to report future AI innovations in medical education."
  },
  {
    "objectID": "2024-10-23-ai-in-medical-education/index.html#go-forth-and-educate",
    "href": "2024-10-23-ai-in-medical-education/index.html#go-forth-and-educate",
    "title": "AI in Medical Education",
    "section": "Go forth and educate!",
    "text": "Go forth and educate!"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#findable",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#findable",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Findable",
    "text": "Findable\nThe first step in (re)using data is to find them. Metadata and data should be easy to find for both humans and computers. Machine-readable metadata are essential for automatic discovery of datasets and services, so this is an essential component of the FAIRification process.\nF1. (Meta)data are assigned a globally unique and persistent identifier\nF2. Data are described with rich metadata (defined by R1 below)\nF3. Metadata clearly and explicitly include the identifier of the data they describe\nF4. (Meta)data are registered or indexed in a searchable resource"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#accessible",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#accessible",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Accessible",
    "text": "Accessible\nOnce the user finds the required data, she/he/they need to know how they can be accessed, possibly including authentication and authorisation.\nA1. (Meta)data are retrievable by their identifier using a standardised communications protocol\nA1.1 The protocol is open, free, and universally implementable\nA1.2 The protocol allows for an authentication and authorisation procedure, where necessary\nA2. Metadata are accessible, even when the data are no longer available"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#interoperable",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#interoperable",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Interoperable",
    "text": "Interoperable\nThe data usually need to be integrated with other data. In addition, the data need to interoperate with applications or workflows for analysis, storage, and processing.\nI1. (Meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation.\nI2. (Meta)data use vocabularies that follow FAIR principles\nI3. (Meta)data include qualified references to other (meta)data"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#reusablereproducible",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#reusablereproducible",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Reusable/Reproducible",
    "text": "Reusable/Reproducible\nThe ultimate goal of FAIR is to optimise the reuse of data. To achieve this, metadata and data should be well-described so that they can be replicated and/or combined in different settings.\nR1. (Meta)data are richly described with a plurality of accurate and relevant attributes\nR1.1. (Meta)data are released with a clear and accessible data usage license\nR1.2. (Meta)data are associated with detailed provenance\nR1.3. (Meta)data meet domain-relevant community standards"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#gene-names-excel",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#gene-names-excel",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Gene Names & Excel",
    "text": "Gene Names & Excel\n\n(Ziemann, Eren, and El-Osta 2016)"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#gene-names-excel-1",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#gene-names-excel-1",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Gene Names & Excel",
    "text": "Gene Names & Excel\n Prevalence of gene name errors in supplementary Excel files. a Percentage of published papers with supplementary gene lists in Excel files affected by gene name errors. b Increase in gene name errors by year (Ziemann, Eren, and El-Osta 2016)"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#excel",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#excel",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Excel",
    "text": "Excel"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#reading",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#reading",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Reading",
    "text": "Reading\nMicrosoft Excel and Google Sheets are powerful and widely used. But there’s a right way and a wrong way to use them, data scientists say. Microsoft Excel and Google Sheets are powerful and widely used. But there’s a right way and a wrong way to use them, data scientists say. (Perkel 2022)"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#questions-and-discussion",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#questions-and-discussion",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Questions and Discussion",
    "text": "Questions and Discussion\n\nSean Davis\nhttps://seandavi.github.io\nhttps://twitter.com/seandavis12\nsean.2.davis@cuanschutz.edu"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#the-data",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#the-data",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "The data",
    "text": "The data\nThe data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models). (Henderson and Velleman 1981)"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#the-data-1",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#the-data-1",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "The data",
    "text": "The data\nA data frame with 32 observations on 11 (numeric) variables.\n\nmpg Miles/(US) gallon\ncyl Number of cylinders\ndisp Displacement (cu.in.)\nhp Gross horsepower\ndrat Rear axle ratio\nwt Weight (1000 lbs)\nqsec 1/4 mile time\nvs Engine (0 = V-shaped, 1 = straight)\nam Transmission (0 = automatic, 1 = manual)\ngear Number of forward gears\ncarb Number of carburetors"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#the-data-2",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#the-data-2",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "The data",
    "text": "The data"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#exercise",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#exercise",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Exercise",
    "text": "Exercise\n\nPreliminaries: login to Orchestra\nShow you around Jupyterlab\nLoad a CSV (comma-separated-value) file containing the mtcars dataset.\nExplore the dataset\n\nText summaries\nPlots"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#login-to-orchestra",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#login-to-orchestra",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Login to Orchestra",
    "text": "Login to Orchestra\n\nhttp://orchestra.cancerdatasci.org"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#references",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/2023-03-08-univ-colorado-bmsc-7812-r-intro.html#references",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "References",
    "text": "References\n\n\n\n\nCechova, Monika. 2020. “Ten Simple Rules for Biologists Initiating a Collaboration with Computer Scientists.” PLoS Computational Biology 16 (10): e1008281. https://doi.org/10.1371/journal.pcbi.1008281.\n\n\nHenderson, Harold V, and Paul F Velleman. 1981. “Building Multiple Regression Models Interactively.” Biometrics 37 (2): 391–411. https://doi.org/10.2307/2530428.\n\n\nMichener, William K. 2015. “Ten Simple Rules for Creating a Good Data Management Plan.” PLoS Computational Biology 11 (10): e1004525. https://doi.org/10.1371/journal.pcbi.1004525.\n\n\nOza, Vishal H, Jordan H Whitlock, Elizabeth J Wilk, Angelina Uno-Antonison, Brandon Wilk, Manavalan Gajapathy, Timothy C Howton, et al. 2023. “Ten Simple Rules for Using Public Biological Data for Your Research.” PLoS Computational Biology 19 (1): e1010749. https://doi.org/10.1371/journal.pcbi.1010749.\n\n\nPerkel, Jeffrey M. 2022. “Six Tips for Better Spreadsheets.” Nature 608 (7921): 229–30. https://doi.org/10.1038/d41586-022-02076-1.\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig. 2013. “Ten Simple Rules for Reproducible Computational Research.” PLoS Computational Biology 9 (10): e1003285. https://doi.org/10.1371/journal.pcbi.1003285.\n\n\nZiemann, Mark, Yotam Eren, and Assam El-Osta. 2016. “Gene Name Errors Are Widespread in the Scientific Literature.” Genome Biology 17 (1): 177. https://doi.org/10.1186/s13059-016-1044-7."
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#findable",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#findable",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Findable",
    "text": "Findable\nThe first step in (re)using data is to find them. Metadata and data should be easy to find for both humans and computers. Machine-readable metadata are essential for automatic discovery of datasets and services, so this is an essential component of the FAIRification process.\nF1. (Meta)data are assigned a globally unique and persistent identifier\nF2. Data are described with rich metadata (defined by R1 below)\nF3. Metadata clearly and explicitly include the identifier of the data they describe\nF4. (Meta)data are registered or indexed in a searchable resource"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#accessible",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#accessible",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Accessible",
    "text": "Accessible\nOnce the user finds the required data, she/he/they need to know how they can be accessed, possibly including authentication and authorisation.\nA1. (Meta)data are retrievable by their identifier using a standardised communications protocol\nA1.1 The protocol is open, free, and universally implementable\nA1.2 The protocol allows for an authentication and authorisation procedure, where necessary\nA2. Metadata are accessible, even when the data are no longer available"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#interoperable",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#interoperable",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Interoperable",
    "text": "Interoperable\nThe data usually need to be integrated with other data. In addition, the data need to interoperate with applications or workflows for analysis, storage, and processing.\nI1. (Meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation.\nI2. (Meta)data use vocabularies that follow FAIR principles\nI3. (Meta)data include qualified references to other (meta)data"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#reusablereproducible",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#reusablereproducible",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Reusable/Reproducible",
    "text": "Reusable/Reproducible\nThe ultimate goal of FAIR is to optimise the reuse of data. To achieve this, metadata and data should be well-described so that they can be replicated and/or combined in different settings.\nR1. (Meta)data are richly described with a plurality of accurate and relevant attributes\nR1.1. (Meta)data are released with a clear and accessible data usage license\nR1.2. (Meta)data are associated with detailed provenance\nR1.3. (Meta)data meet domain-relevant community standards"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#gene-names-excel",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#gene-names-excel",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Gene Names & Excel",
    "text": "Gene Names & Excel\n\n(Ziemann, Eren, and El-Osta 2016)"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#gene-names-excel-1",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#gene-names-excel-1",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Gene Names & Excel",
    "text": "Gene Names & Excel\n Prevalence of gene name errors in supplementary Excel files. a Percentage of published papers with supplementary gene lists in Excel files affected by gene name errors. b Increase in gene name errors by year (Ziemann, Eren, and El-Osta 2016)"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#excel",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#excel",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Excel",
    "text": "Excel"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#reading",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#reading",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Reading",
    "text": "Reading\nMicrosoft Excel and Google Sheets are powerful and widely used. But there’s a right way and a wrong way to use them, data scientists say. Microsoft Excel and Google Sheets are powerful and widely used. But there’s a right way and a wrong way to use them, data scientists say. (Perkel 2022)"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#questions-and-discussion",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#questions-and-discussion",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Questions and Discussion",
    "text": "Questions and Discussion\n\nSean Davis\nhttps://seandavi.github.io\nhttps://twitter.com/seandavis12\nsean.2.davis@cuanschutz.edu"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#the-data",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#the-data",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "The data",
    "text": "The data\nThe data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models). (Henderson and Velleman 1981)"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#the-data-1",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#the-data-1",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "The data",
    "text": "The data\nA data frame with 32 observations on 11 (numeric) variables.\n\nmpg Miles/(US) gallon\ncyl Number of cylinders\ndisp Displacement (cu.in.)\nhp Gross horsepower\ndrat Rear axle ratio\nwt Weight (1000 lbs)\nqsec 1/4 mile time\nvs Engine (0 = V-shaped, 1 = straight)\nam Transmission (0 = automatic, 1 = manual)\ngear Number of forward gears\ncarb Number of carburetors"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#the-data-2",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#the-data-2",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "The data",
    "text": "The data"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#exercise",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#exercise",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Exercise",
    "text": "Exercise\n\nPreliminaries: login to Orchestra\nShow you around Jupyterlab\nLoad a CSV (comma-separated-value) file containing the mtcars dataset.\nExplore the dataset\n\nText summaries\nPlots"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#login-to-orchestra",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#login-to-orchestra",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "Login to Orchestra",
    "text": "Login to Orchestra\n\nhttp://orchestra.cancerdatasci.org"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#references",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/index.html#references",
    "title": "Reproducible, reusable, and shareable concepts in computational research",
    "section": "References",
    "text": "References\n\n\n\n\nCechova, Monika. 2020. “Ten Simple Rules for Biologists Initiating a Collaboration with Computer Scientists.” PLoS Computational Biology 16 (10): e1008281. https://doi.org/10.1371/journal.pcbi.1008281.\n\n\nHenderson, Harold V, and Paul F Velleman. 1981. “Building Multiple Regression Models Interactively.” Biometrics 37 (2): 391–411. https://doi.org/10.2307/2530428.\n\n\nMichener, William K. 2015. “Ten Simple Rules for Creating a Good Data Management Plan.” PLoS Computational Biology 11 (10): e1004525. https://doi.org/10.1371/journal.pcbi.1004525.\n\n\nOza, Vishal H, Jordan H Whitlock, Elizabeth J Wilk, Angelina Uno-Antonison, Brandon Wilk, Manavalan Gajapathy, Timothy C Howton, et al. 2023. “Ten Simple Rules for Using Public Biological Data for Your Research.” PLoS Computational Biology 19 (1): e1010749. https://doi.org/10.1371/journal.pcbi.1010749.\n\n\nPerkel, Jeffrey M. 2022. “Six Tips for Better Spreadsheets.” Nature 608 (7921): 229–30. https://doi.org/10.1038/d41586-022-02076-1.\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig. 2013. “Ten Simple Rules for Reproducible Computational Research.” PLoS Computational Biology 9 (10): e1003285. https://doi.org/10.1371/journal.pcbi.1003285.\n\n\nZiemann, Mark, Yotam Eren, and Assam El-Osta. 2016. “Gene Name Errors Are Widespread in the Scientific Literature.” Genome Biology 17 (1): 177. https://doi.org/10.1186/s13059-016-1044-7."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#center",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#center",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Overview",
    "text": "Overview\n\n\n\nBrief history and background\nWhat are these things?\nMachine learning\nBiases and ethics"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#brief-history",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#brief-history",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Brief History",
    "text": "Brief History\n\n\nhttps://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#the-hype-cycle",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#the-hype-cycle",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "The hype cycle",
    "text": "The hype cycle\n\nThe Gartner Hype Cycle."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#the-hype-cycle-circa-2016",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#the-hype-cycle-circa-2016",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "The hype cycle (circa 2016)",
    "text": "The hype cycle (circa 2016)\n\nThe Gartner Hype Cycle."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#what-is-artificial-intelligence",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#what-is-artificial-intelligence",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "What is Artificial Intelligence?",
    "text": "What is Artificial Intelligence?\nThe theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#what-is-machine-learning",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#what-is-machine-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\nThe study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning systems give the computer the ability to learn without being explicitly programmed rules."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#what-is-deep-learning",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#what-is-deep-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "What is Deep Learning?",
    "text": "What is Deep Learning?\nMachine learning algorithms that are inspired by the structure and function of the brain. Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is often unstructured (i.e., text or images)."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#ai-vs.-ml-vs.-deep-learning",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#ai-vs.-ml-vs.-deep-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "AI vs. ML vs. Deep Learning",
    "text": "AI vs. ML vs. Deep Learning\n\n\nArtificialIntelligence\n\n\nMachineLearning\n\n\nDeepLearning"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#ai-vs.-ml-vs.-deep-learning-1",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#ai-vs.-ml-vs.-deep-learning-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "AI vs. ML vs. Deep Learning",
    "text": "AI vs. ML vs. Deep Learning\n\n\nArtificialIntelligence\n\n\nMachineLearning\n\n\nDeepLearning"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#applications-in-healthcare",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#applications-in-healthcare",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Applications in healthcare",
    "text": "Applications in healthcare\n\nThe data types considered in the artificial intelligence artificial (AI) literature. The comparison is obtained through searching the diagnosis techniques in the AI literature on the PubMed database(Jiang et al. 2017, fig. 1)."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#applications-in-healthcare-1",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#applications-in-healthcare-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Applications in healthcare",
    "text": "Applications in healthcare\n\nThe leading 10 disease types considered in the artificial intelligence (AI) literature. The first vocabularies in the disease names are displayed. The comparison is obtained through searching the disease types in the AI literature on PubMed (Jiang et al. 2017, fig. 3)."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#applications-in-healthcare-2",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#applications-in-healthcare-2",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Applications in healthcare",
    "text": "Applications in healthcare\n\nfrom (Challen et al. 2019)"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#classes-of-machine-learning",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#classes-of-machine-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Classes of Machine Learning",
    "text": "Classes of Machine Learning\n\nBroad classes of machine learning."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#a-map-of-machine-learning-approaches",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#a-map-of-machine-learning-approaches",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "A map of machine learning approaches",
    "text": "A map of machine learning approaches\n\n\nhttps://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#supervised-learning",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#supervised-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#supervised-learning-1",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#supervised-learning-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\n\nSupervised learning."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#supervised-learning-2",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#supervised-learning-2",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\n\nSupervised learning."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#supervised-learning-3",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#supervised-learning-3",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\n\nSupervised learning."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#classification",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#classification",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Classification",
    "text": "Classification"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#regression",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#regression",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Regression",
    "text": "Regression\n\nApplication of regression to predict eutrophil count using the signatures learned from public databases(Oh et al. 2022, fig. 4)"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#developing-a-model",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#developing-a-model",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Developing a model",
    "text": "Developing a model\n\nDevelop question!!!\nCollect data\nSplit data into training and test\nTrain model\n\nestimating model parameters (i.e. training models)\ndetermining the values of tuning parameters that cannot be directly calculated from the data\n\nTest model\n\ncalculating the performance of the final model that will generalize to new data\n\nPossibly validate model\nDeploy"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#algorithms-for-supervised-learning",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#algorithms-for-supervised-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nLinear regression."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#algorithms-for-supervised-learning-1",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#algorithms-for-supervised-learning-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nAnscombe’s Quartet\nhttps://en.wikipedia.org/wiki/Anscombe%27s_quartet"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#algorithms-for-supervised-learning-2",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#algorithms-for-supervised-learning-2",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nClassification and Regression Trees (CART)."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#algorithms-for-supervised-learning-3",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#algorithms-for-supervised-learning-3",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nK-nearest neighbor (kNN) algorithm."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#algorithms-for-supervised-learning-4",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#algorithms-for-supervised-learning-4",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nRandom Forests."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#algorithms-for-supervised-learning-5",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#algorithms-for-supervised-learning-5",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nDeep learning."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#applying-supervised-learning-algorithms",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#applying-supervised-learning-algorithms",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Applying Supervised Learning Algorithms",
    "text": "Applying Supervised Learning Algorithms\n\nThe mlr3 ecosystem in R."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#unsupervised-learning",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#unsupervised-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Unsupervised Learning",
    "text": "Unsupervised Learning\n\nUnsupervised learning."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#clustering",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#clustering",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nGene expression measurements."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#classes-of-unsupervised-learning-algorithms",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#classes-of-unsupervised-learning-algorithms",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Classes of unsupervised learning algorithms",
    "text": "Classes of unsupervised learning algorithms\n\n\n\n\n\nClustering.\n\n\n\n\n\n\nDimensionality reduction."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#clustering-1",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#clustering-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nThinking about similarities and differences"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#clustering-2",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#clustering-2",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#clustering-3",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#clustering-3",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#clustering-4",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#clustering-4",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#dimensionality-reduction",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#dimensionality-reduction",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\n\nSchematic PCA."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#dimensionality-reduction-1",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#dimensionality-reduction-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\n\nUsing dimensionality reduction to explore 22,000 dimensions of gene expression data on 280 samples.\nhttps://seandavi.github.io/ITR/geoquery_mds.html"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#machine-learning-review",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#machine-learning-review",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Machine Learning Review",
    "text": "Machine Learning Review\n\nSupervised Learning\n\nClassification\nRegression\n\nUnsupervised Learning\n\nClustering\nDimensionality Reduction"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#resources",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#resources",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Resources",
    "text": "Resources\n\nRecent reviews\n\nMachine Learning in Genomic Medicine: A Review of Computational Problems and Data Sets\nOpportunities And Obstacles For Deep Learning In Biology And Medicine\n\nBlogs and online materials\n\nhttps://blog.recast.ai/machine-learning-algorithms/\nhttps://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A\nhttps://www.youtube.com/c/joshstarmer\n\nMachine Learning in R\n\nhttps://www.datacamp.com/community/tutorials/machine-learning-in-r\nhttps://daviddalpiaz.github.io/r4sl/"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#ethical-challenges-in-ai-ml",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#ethical-challenges-in-ai-ml",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Ethical challenges in AI & ML",
    "text": "Ethical challenges in AI & ML\n\nHow do we address ethical and moral decisionmaking for individuals, groups, and society?\nhttps://sitn.hms.harvard.edu/flash/2017/hold-artificial-intelligence-accountable/"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#biases-in-aiml",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#biases-in-aiml",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Biases in AI/ML",
    "text": "Biases in AI/ML\n\nTypes and sources of bias in big data and AI/ML applications in healthcare (Norori et al. 2021). Bias in the medical field can be dissected along three directions: data-driven, algorithmic, and human."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#addressing-bias",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#addressing-bias",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Addressing Bias",
    "text": "Addressing Bias\n\n\n\n\n Open science practices can assist in moving toward fairness in AI for health care (Norori et al. 2021). These include:\n\nparticipant-centered development of AI algorithms and participatory science;\nresponsible data sharing and inclusive data standards to support interoperability;\ncode sharing, including sharing of AI algorithms that can synthesize underrepresented data to address bias and improve health outcomes.\n\n\nEach of these is harder and more expensive than it sounds."
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#questions-and-discussion",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#questions-and-discussion",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Questions and Discussion",
    "text": "Questions and Discussion\n\nSean Davis\nhttps://seandavi.github.io\nhttps://twitter.com/seandavis12\nsean.2.davis@cuanschutz.edu"
  },
  {
    "objectID": "2023-07-11-CSHLData-AI-ML-intro/index.html#references",
    "href": "2023-07-11-CSHLData-AI-ML-intro/index.html#references",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "References",
    "text": "References\n\n\n\n\nChallen, Robert, Joshua Denny, Martin Pitt, Luke Gompels, Tom Edwards, and Krasimira Tsaneva-Atanasova. 2019. “Artificial Intelligence, Bias and Clinical Safety.” BMJ Quality & Safety 28 (3): 231–37.\n\n\nJiang, Fei, Yong Jiang, Hui Zhi, Yi Dong, Hao Li, Sufeng Ma, Yilong Wang, Qiang Dong, Haipeng Shen, and Yongjun Wang. 2017. “Artificial Intelligence in Healthcare: Past, Present and Future.” Stroke and Vascular Neurology 2 (4): 230–43. https://doi.org/10.1136/svn-2017-000101.\n\n\nNorori, Natalia, Qiyang Hu, Florence Marcelle Aellen, Francesca Dalia Faraci, and Athina Tzovara. 2021. “Addressing Bias in Big Data and AI for Health Care: A Call for Open Science.” Patterns (New York, N.Y.) 2 (10): 100347. https://doi.org/10.1016/j.patter.2021.100347.\n\n\nOh, Sehyun, Ludwig Geistlinger, Marcel Ramos, Daniel Blankenberg, Marius van den Beek, Jaclyn N Taroni, Vincent J Carey, Casey S Greene, Levi Waldron, and Sean Davis. 2022. “GenomicSuperSignature Facilitates Interpretation of RNA-seq Experiments Through Robust, Efficient Comparison to Public Databases.” Nature Communications 13 (1): 3695. https://doi.org/10.1038/s41467-022-31411-3."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#section",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#section",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "",
    "text": "Scan for CME Credit"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#center",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#center",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Overview",
    "text": "Overview\n\n\n\nBrief history and background\nWhat are these things?\nMachine learning\nBiases and ethics"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#brief-history",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#brief-history",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Brief History",
    "text": "Brief History\n\n\nhttps://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#the-hype-cycle",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#the-hype-cycle",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "The hype cycle",
    "text": "The hype cycle\n\nThe Gartner Hype Cycle."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#the-hype-cycle-circa-2016",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#the-hype-cycle-circa-2016",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "The hype cycle (circa 2016)",
    "text": "The hype cycle (circa 2016)\n\nThe Gartner Hype Cycle."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#what-is-artificial-intelligence",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#what-is-artificial-intelligence",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "What is Artificial Intelligence?",
    "text": "What is Artificial Intelligence?\nThe theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#what-is-machine-learning",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#what-is-machine-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\nThe study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning systems give the computer the ability to learn without being explicitly programmed rules."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#what-is-deep-learning",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#what-is-deep-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "What is Deep Learning?",
    "text": "What is Deep Learning?\nMachine learning algorithms that are inspired by the structure and function of the brain. Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is often unstructured (i.e., text or images)."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#ai-vs.-ml-vs.-deep-learning",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#ai-vs.-ml-vs.-deep-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "AI vs. ML vs. Deep Learning",
    "text": "AI vs. ML vs. Deep Learning\n\n\nArtificialIntelligence\n\n\nMachineLearning\n\n\nDeepLearning"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#ai-vs.-ml-vs.-deep-learning-1",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#ai-vs.-ml-vs.-deep-learning-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "AI vs. ML vs. Deep Learning",
    "text": "AI vs. ML vs. Deep Learning\n\n\nArtificialIntelligence\n\n\nMachineLearning\n\n\nDeepLearning"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#applications-in-healthcare",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#applications-in-healthcare",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Applications in healthcare",
    "text": "Applications in healthcare\n\nThe data types considered in the artificial intelligence artificial (AI) literature. The comparison is obtained through searching the diagnosis techniques in the AI literature on the PubMed database(Jiang et al. 2017, fig. 1)."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#applications-in-healthcare-1",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#applications-in-healthcare-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Applications in healthcare",
    "text": "Applications in healthcare\n\nThe leading 10 disease types considered in the artificial intelligence (AI) literature. The first vocabularies in the disease names are displayed. The comparison is obtained through searching the disease types in the AI literature on PubMed (Jiang et al. 2017, fig. 3)."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#applications-in-healthcare-2",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#applications-in-healthcare-2",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Applications in healthcare",
    "text": "Applications in healthcare\n\nfrom (Challen et al. 2019)"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#classes-of-machine-learning",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#classes-of-machine-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Classes of Machine Learning",
    "text": "Classes of Machine Learning\n\nBroad classes of machine learning."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#a-map-of-machine-learning-approaches",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#a-map-of-machine-learning-approaches",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "A map of machine learning approaches",
    "text": "A map of machine learning approaches\n\n\nhttps://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#supervised-learning",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#supervised-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\n\nSupervised learning."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#classification",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#classification",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Classification",
    "text": "Classification"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#regression",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#regression",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Regression",
    "text": "Regression\n\nApplication of regression to predict eutrophil count using the signatures learned from public databases(Oh et al. 2022, fig. 4)"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#supervised-learning-process",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#supervised-learning-process",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Supervised Learning Process",
    "text": "Supervised Learning Process\n\nDevelop question!!!\nCollect data\nSplit data into training and test (and possibly validation) sets\nTrain model\n\nchoose model parameters (i.e. training models) that minimize the error on the training data\ndetermining the values of tuning parameters that cannot be directly calculated from the data (e.g. the number of trees in a random forest)\n\nTest model\n\ncalculating the performance of the final model that will generalize to new data\n\nPossibly validate model (on new data)\nDeploy (put into practice)"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#algorithms-for-supervised-learning",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#algorithms-for-supervised-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nLinear regression."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#algorithms-for-supervised-learning-1",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#algorithms-for-supervised-learning-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nAnscombe’s Quartet\nhttps://en.wikipedia.org/wiki/Anscombe%27s_quartet"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#algorithms-for-supervised-learning-2",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#algorithms-for-supervised-learning-2",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nClassification and Regression Trees (CART)."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#algorithms-for-supervised-learning-3",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#algorithms-for-supervised-learning-3",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nK-nearest neighbor (kNN) algorithm."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#algorithms-for-supervised-learning-4",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#algorithms-for-supervised-learning-4",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nRandom Forests."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#algorithms-for-supervised-learning-5",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#algorithms-for-supervised-learning-5",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nDeep learning."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#applying-supervised-learning-algorithms",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#applying-supervised-learning-algorithms",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Applying Supervised Learning Algorithms",
    "text": "Applying Supervised Learning Algorithms\n\nThe mlr3 ecosystem in R."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#unsupervised-learning",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#unsupervised-learning",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Unsupervised Learning",
    "text": "Unsupervised Learning\n\nUnsupervised learning."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#clustering",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#clustering",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nGene expression measurements."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#classes-of-unsupervised-learning-algorithms",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#classes-of-unsupervised-learning-algorithms",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Classes of unsupervised learning algorithms",
    "text": "Classes of unsupervised learning algorithms\n\n\n\n\n\nClustering.\n\n\n\n\n\n\nDimensionality reduction."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#clustering-1",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#clustering-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nThinking about similarities and differences"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#clustering-2",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#clustering-2",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#clustering-3",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#clustering-3",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#clustering-4",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#clustering-4",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#dimensionality-reduction",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#dimensionality-reduction",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\n\nSchematic PCA."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#dimensionality-reduction-1",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#dimensionality-reduction-1",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\n\nUsing dimensionality reduction to explore 22,000 dimensions of gene expression data on 280 samples.\nhttps://seandavi.github.io/ITR/geoquery_mds.html"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#machine-learning-review",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#machine-learning-review",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Machine Learning Review",
    "text": "Machine Learning Review\n\nSupervised Learning\n\nClassification\nRegression\n\nUnsupervised Learning\n\nClustering\nDimensionality Reduction"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#resources",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#resources",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Resources",
    "text": "Resources\n\nRecent reviews\n\nMachine Learning in Genomic Medicine: A Review of Computational Problems and Data Sets\nOpportunities And Obstacles For Deep Learning In Biology And Medicine\n\nHands-on Tutorials\n\nhttp://rpubs.com/seandavi/MLBasics\nhttps://seandavi.github.io/ITR/machine_learning_mlr3.html\nMany, many more\n\nBlogs and online materials\n\nhttps://blog.recast.ai/machine-learning-algorithms/\nhttps://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A\nhttps://www.youtube.com/c/joshstarmer\n\nMachine Learning in R\n\nhttps://www.datacamp.com/community/tutorials/machine-learning-in-r\nhttps://daviddalpiaz.github.io/r4sl/"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#ethical-challenges-in-ai-ml",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#ethical-challenges-in-ai-ml",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Ethical challenges in AI & ML",
    "text": "Ethical challenges in AI & ML\n\nHow do we address ethical and moral decisionmaking for individuals, groups, and society?\nhttps://sitn.hms.harvard.edu/flash/2017/hold-artificial-intelligence-accountable/"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#biases-in-aiml",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#biases-in-aiml",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Biases in AI/ML",
    "text": "Biases in AI/ML\n\nTypes and sources of bias in big data and AI/ML applications in healthcare (Norori et al. 2021). Bias in the medical field can be dissected along three directions: data-driven, algorithmic, and human."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#addressing-bias",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#addressing-bias",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Addressing Bias",
    "text": "Addressing Bias\n\n\n\n\n Open science practices can assist in moving toward fairness in AI for health care (Norori et al. 2021). These include:\n\nparticipant-centered development of AI algorithms and participatory science;\nresponsible data sharing and inclusive data standards to support interoperability;\ncode sharing, including sharing of AI algorithms that can synthesize underrepresented data to address bias and improve health outcomes.\n\n\nEach of these is harder and more expensive than it sounds."
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#questions-and-discussion",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#questions-and-discussion",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "Questions and Discussion",
    "text": "Questions and Discussion\n\nSean Davis\nhttps://seandavi.github.io\nhttps://twitter.com/seandavis12\nsean.2.davis@cuanschutz.edu"
  },
  {
    "objectID": "2022-09-06-CU-SOM-AI-ML-intro/index.html#references",
    "href": "2022-09-06-CU-SOM-AI-ML-intro/index.html#references",
    "title": "Artificial Intelligence & Machine Learning",
    "section": "References",
    "text": "References\n\n\n\n\nChallen, Robert, Joshua Denny, Martin Pitt, Luke Gompels, Tom Edwards, and Krasimira Tsaneva-Atanasova. 2019. “Artificial Intelligence, Bias and Clinical Safety.” BMJ Quality & Safety 28 (3): 231–37.\n\n\nJiang, Fei, Yong Jiang, Hui Zhi, Yi Dong, Hao Li, Sufeng Ma, Yilong Wang, Qiang Dong, Haipeng Shen, and Yongjun Wang. 2017. “Artificial Intelligence in Healthcare: Past, Present and Future.” Stroke and Vascular Neurology 2 (4): 230–43. https://doi.org/10.1136/svn-2017-000101.\n\n\nNorori, Natalia, Qiyang Hu, Florence Marcelle Aellen, Francesca Dalia Faraci, and Athina Tzovara. 2021. “Addressing Bias in Big Data and AI for Health Care: A Call for Open Science.” Patterns (New York, N.Y.) 2 (10): 100347. https://doi.org/10.1016/j.patter.2021.100347.\n\n\nOh, Sehyun, Ludwig Geistlinger, Marcel Ramos, Daniel Blankenberg, Marius van den Beek, Jaclyn N Taroni, Vincent J Carey, Casey S Greene, Levi Waldron, and Sean Davis. 2022. “GenomicSuperSignature Facilitates Interpretation of RNA-seq Experiments Through Robust, Efficient Comparison to Public Databases.” Nature Communications 13 (1): 3695. https://doi.org/10.1038/s41467-022-31411-3."
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/hands-on.html",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/hands-on.html",
    "title": "Hands-on with R in Jupyter",
    "section": "",
    "text": "This tutorial is intended for beginners who are new to R programming. In this tutorial, we will cover the following topics:\nlibrary(ggplot2)\noptions(repr.plot.width = 12, repr.plot.height = 12)"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/hands-on.html#loading-a-csv-file",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/hands-on.html#loading-a-csv-file",
    "title": "Hands-on with R in Jupyter",
    "section": "Loading a CSV File",
    "text": "Loading a CSV File\nThe mtcars dataset is a built-in dataset in R that contains information on various car models. To load this dataset, we can use the following command:\n\ndata(mtcars)\n\nIf you have a csv file containing the mtcars dataset, you can load it using the following command:\n\nmtcars &lt;- read.csv(\"mtcars.csv\")\n\nReplace “path/to/file.csv” with the actual file path and name."
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/hands-on.html#data-exploration",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/hands-on.html#data-exploration",
    "title": "Hands-on with R in Jupyter",
    "section": "Data Exploration",
    "text": "Data Exploration\nOnce we have loaded the dataset, we can explore it using the summary, head, and tail functions.\nThe mtcars thing is now a variable in R. We can ask R to show us the value by just typing:\n\nmtcars\n\nFor larget datasets, it can be helpful to look at smaller parts such as the head, or first values, and tail, or last values.\n\nhead(mtcars)\n\n\ntail(mtcars)\n\nThe summary function provides a quick summary of the dataset, including minimum and maximum values, quartiles, and means:\n\nsummary(mtcars)\n\n\n## Plotting\n\n\npairs(mtcars[,1:5])\n\nDelete this text and use this block to write about what you see above.\n\nggplot2\n\nggplot(mtcars,aes(x=disp,y=hp)) + geom_point(aes(size=mpg,color=wt))\n\nIn the plot above, try changing the variables in the plot command to explore variable relationships."
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/hands-on.html#reproducible-research",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/hands-on.html#reproducible-research",
    "title": "Hands-on with R in Jupyter",
    "section": "Reproducible research!",
    "text": "Reproducible research!\nAt this point, we have an Jupyter Notebook, not unlike a lab notebook. We can save our experiments, including both the procedure and the results. If we change any procedure, we get new results.\nWhen you are satisfied with what you have put together, go to File -&gt;&gt; Save and Export Notebook as -&gt;&gt; pdf. Magically, you’ll have everything here in a PDF. Make any changes, rerun the cell, and then re-export to get the latest version."
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/hands-on.html#assignment-and-expressions-in-r",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/hands-on.html#assignment-and-expressions-in-r",
    "title": "Hands-on with R in Jupyter",
    "section": "Assignment and Expressions in R",
    "text": "Assignment and Expressions in R\nIn R, we can use the assignment operator &lt;- to assign values to variables. For example:\n\nx &lt;- 10\ny &lt;- \"hello\"\nz &lt;- c(1, 2, 3)\n\n\nx\n\n\ny\n\n\nz\n\nIn the above code, we assign the value 10 to the variable x, the string \"hello\" to the variable y, and a vector of numbers 1, 2, and 3 to the variable z.\nWe can also use the equal sign = as an alternative to &lt;-. For example:\n\nx = 10\ny = \"hello\"\nz = c(1, 2, 3)\n\nBoth &lt;- and = are used for assignment and can be used interchangeably.\nWe can perform arithmetic operations on variables and values in R. For example:\n\nx &lt;- 10\ny &lt;- 5\nz &lt;- x + y\n\nIn the above code, we add the values of x and y and assign the result to the variable z.\nR supports many arithmetic operators, including +, -, *, /, ^, and %/% (integer division).\nWe can also use logical operators in R to perform comparisons. For example:\n\nx &lt;- 10\ny &lt;- 5\nx &gt; y\n\nIn the above code, we compare the values of x and y using the greater than operator &gt; and the result is TRUE.\nR also has a number of built-in functions that we can use. For example:\n\nsqrt(16)\n\nIn the above code, we use the sqrt() function to calculate the square root of 16.\nExpressions in R can be written using a combination of variables, values, and operators. For example:\n\nx &lt;- 10\ny &lt;- 5\nz &lt;- x + y\na &lt;- z * 2\n\nIn the above code, we first add the values of x and y and assign the result to the variable z. We then multiply the value of z by 2 and assign the result to the variable a.\n\na"
  },
  {
    "objectID": "2023-03-08-univ-colorado-bmsc-7812-r-intro/stuff.html",
    "href": "2023-03-08-univ-colorado-bmsc-7812-r-intro/stuff.html",
    "title": "Talks",
    "section": "",
    "text": "library(ggplot2)\noptions(repr.plot.width = 12, repr.plot.height = 12)\n\n\nhead(mtcars)\n\n\nA data.frame: 6 × 11\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\ntail(mtcars)\n\n\nA data.frame: 6 × 11\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nPorsche 914-2\n26.0\n4\n120.3\n91\n4.43\n2.140\n16.7\n0\n1\n5\n2\n\n\nLotus Europa\n30.4\n4\n95.1\n113\n3.77\n1.513\n16.9\n1\n1\n5\n2\n\n\nFord Pantera L\n15.8\n8\n351.0\n264\n4.22\n3.170\n14.5\n0\n1\n5\n4\n\n\nFerrari Dino\n19.7\n6\n145.0\n175\n3.62\n2.770\n15.5\n0\n1\n5\n6\n\n\nMaserati Bora\n15.0\n8\n301.0\n335\n3.54\n3.570\n14.6\n0\n1\n5\n8\n\n\nVolvo 142E\n21.4\n4\n121.0\n109\n4.11\n2.780\n18.6\n1\n1\n4\n2\n\n\n\n\n\n\nsummary(mtcars)\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\n\n\npairs(mtcars[,1:5])\n\n\n\n\n\n\n\n\n\nlibrary(ggpairs)\n\nERROR: Error in library(ggpairs): there is no package called ‘ggpairs’\n\nError in library(ggpairs): there is no package called ‘ggpairs’\nTraceback:\n\n1. library(ggpairs)"
  },
  {
    "objectID": "2023-05-19-uccc-sd-retreat/2023-05-19-uccc-sd-retreat.html#quarto",
    "href": "2023-05-19-uccc-sd-retreat/2023-05-19-uccc-sd-retreat.html#quarto",
    "title": "2023-05-19-uccc-sd-retreat",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#introduction",
    "href": "2024-10-30-ai-history/index.html#introduction",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Introduction",
    "text": "Introduction\n\nArtificial Intelligence (AI) and Machine Learning (ML) have a rich history\nFrom early concepts to modern applications\nThis presentation covers key milestones and breakthroughs"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#early-beginnings-1940s-1950s",
    "href": "2024-10-30-ai-history/index.html#early-beginnings-1940s-1950s",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Early Beginnings (1940s-1950s)",
    "text": "Early Beginnings (1940s-1950s)\n\n\n\n1936: Turing and the Computable Numbers (Turing 1936)\n1943: McCulloch and Pitts create a computational model for neural networks\n1950: Alan Turing proposes the Turing Test (Turing 1950) and Paper\n1956: Dartmouth Conference coins the term “Artificial Intelligence”"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#turing-and-the-computable-numbers",
    "href": "2024-10-30-ai-history/index.html#turing-and-the-computable-numbers",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "1936: Turing and the Computable Numbers",
    "text": "1936: Turing and the Computable Numbers\n\nAlan Turing’s 1936 paper, “On Computable Numbers, with an Application to the Entscheidungsproblem”, introduced the idea of computable numbers and the Universal Turing Machine, and laid the theoretical foundation for modern computing.\nhttps://londmathsoc.onlinelibrary.wiley.com/doi/abs/10.1112/plms/s2-42.1.230"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#mcculloch-and-pitts-neuron",
    "href": "2024-10-30-ai-history/index.html#mcculloch-and-pitts-neuron",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "1943: McCulloch and Pitts Neuron",
    "text": "1943: McCulloch and Pitts Neuron\n\n\n\n\n\nWarren McCulloch (neurophysiologist) and Walter Pitts (logician)"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#mcculloch-and-pitts-neuron-1",
    "href": "2024-10-30-ai-history/index.html#mcculloch-and-pitts-neuron-1",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "1943: McCulloch and Pitts Neuron",
    "text": "1943: McCulloch and Pitts Neuron\n\n\n\n\n\n\n\nWarren McCulloch (neurophysiologist) and Walter Pitts (logician)"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#the-turing-test",
    "href": "2024-10-30-ai-history/index.html#the-turing-test",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "1950: The Turing Test",
    "text": "1950: The Turing Test\n\nWho’s the real human?"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#i-robot-by-isaac-asimov",
    "href": "2024-10-30-ai-history/index.html#i-robot-by-isaac-asimov",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "“I, Robot” by Isaac Asimov",
    "text": "“I, Robot” by Isaac Asimov\n\n\n\nPublished in 1950 by Gnome Press\nCollection of nine science fiction short stories\nOriginally appeared in super-science fiction magazines (1940-1950)\nIntroduced the concept of positronic robots and the Three Laws of Robotics\n\n\n\nAsimov (1950)"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#the-three-laws-of-robotics",
    "href": "2024-10-30-ai-history/index.html#the-three-laws-of-robotics",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "The Three Laws of Robotics",
    "text": "The Three Laws of Robotics\n\nA robot may not injure a human being or, through inaction, allow a human being to come to harm.\nA robot must obey the orders given it by human beings except where such orders would conflict with the First Law.\nA robot must protect its own existence as long as such protection does not conflict with the First or Second Laws.\n\n\nAsimov later added the Zeroth Law that superseded the others:\n\nA robot may not harm humanity, or, by inaction, allow humanity to come to harm.\n\n\n\nThese laws have become a cornerstone in discussions about AI ethics and safety."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#i-robots-influence-on-modern-ai",
    "href": "2024-10-30-ai-history/index.html#i-robots-influence-on-modern-ai",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "“I, Robot”’s Influence on Modern AI",
    "text": "“I, Robot”’s Influence on Modern AI\n\nSparked discussions on machine ethics and AI safety\nInfluenced researchers to consider ethical implications of AI development\nConcept of “friendly AI” draws parallels to Asimov’s laws\nChallenges presented in stories mirror real-world AI alignment problems"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#the-dartmouth-conference",
    "href": "2024-10-30-ai-history/index.html#the-dartmouth-conference",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "1956: The Dartmouth Conference",
    "text": "1956: The Dartmouth Conference\nThe Dartmouth Conference, held in the summer of 1956, is considered the birthplace of artificial intelligence. The conference was organized by John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon, who invited researchers to discuss the potential of creating machines that could simulate human intelligence.\n\nMarvin Minsky, Claude Shannon, Ray Solomonoff and other scientists at the Dartmouth Summer Research Project on Artificial Intelligence (Photo: Margaret Minsky)."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#the-golden-years-1956-1974",
    "href": "2024-10-30-ai-history/index.html#the-golden-years-1956-1974",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "The Golden Years (1956-1974)",
    "text": "The Golden Years (1956-1974)\n\nDevelopment of early AI programs\n1957: Frank Rosenblatt develops the Perceptron\n1964: ELIZA, one of the first chatbots, is created by Joseph Weizenbaum"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#the-perceptron",
    "href": "2024-10-30-ai-history/index.html#the-perceptron",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "1957: The Perceptron",
    "text": "1957: The Perceptron"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#eliza-one-of-the-first-chatbots",
    "href": "2024-10-30-ai-history/index.html#eliza-one-of-the-first-chatbots",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "1964: ELIZA, one of the first chatbots",
    "text": "1964: ELIZA, one of the first chatbots\n\n\n\n\n\n\n\n\nAlthough ELIZA was limited in terms of actual understanding, it marked an important milestone in the development of AI and human-computer interaction, showing how conversation-based interfaces could influence the perception of intelligence.\n\n\nELIZA was one of the earliest chatbots, developed in the mid-1960s by Joseph Weizenbaum, a computer scientist at MIT. The program was designed to simulate a conversation between a human and a machine, and it did so by using pattern matching and substitution methodology, a simple but effective form of natural language processing.\nELIZA’s most famous script was called “DOCTOR,” which mimicked a Rogerian psychotherapist. In this role, ELIZA would take users’ input and reflect their statements back to them in a way that encouraged further conversation. For example, if a user said, “I’m feeling sad today,” ELIZA might respond with, “Why do you think you’re feeling sad today?”\nWhile ELIZA’s responses were largely superficial, many users were surprised at how human-like they seemed. Weizenbaum created ELIZA to demonstrate how easily people could attribute human-like understanding to a machine, even when its responses were formulaic. He was struck by how quickly people became emotionally attached to the program, despite knowing it was not genuinely intelligent.\nAlthough ELIZA was limited in terms of actual understanding, it marked an important milestone in the development of AI and human-computer interaction, showing how conversation-based interfaces could influence the perception of intelligence."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#what-is-an-expert-system",
    "href": "2024-10-30-ai-history/index.html#what-is-an-expert-system",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "What is an Expert System?",
    "text": "What is an Expert System?\n\nDefinition: Computer program that emulates decision-making ability of a human expert\nKey Components:\n\nKnowledge Base: Contains domain-specific information and rules\nInference Engine: Applies rules to the knowledge to derive new information\nUser Interface: Allows non-expert users to interact with the system\n\nCharacteristics:\n\nSolves complex problems by reasoning through bodies of knowledge\nSeparates domain knowledge from the reasoning mechanism\nCan explain its decisions and reasoning"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#what-is-an-expert-system-1",
    "href": "2024-10-30-ai-history/index.html#what-is-an-expert-system-1",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "What is an Expert System?",
    "text": "What is an Expert System?\n\nApplications:\n\nMedical diagnosis (e.g., MYCIN)\nFinancial planning\nManufacturing process control\nScientific analysis\n\nAdvantages:\n\nConsistent and accurate decisions\nPreservation of expert knowledge\nAbility to handle complex scenarios\n\nLimitations:\n\nLimited to specific domains (narrow AI)\nDifficulty in capturing tacit knowledge\nMay struggle with unusual or unprecedented situations"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#example-expert-system-mycin",
    "href": "2024-10-30-ai-history/index.html#example-expert-system-mycin",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Example Expert system: MYCIN",
    "text": "Example Expert system: MYCIN\n\nDeveloped in the early 1970s at Stanford University\nOne of the first rule-based expert systems in medicine\nPurpose: Assist physicians in diagnosing and treating bacterial infections\nFocused on bloodstream infections (bacteremia and meningitis)\nNamed after antibiotics (many of which end in “-mycin”)"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#mycin-key-features-and-functionality",
    "href": "2024-10-30-ai-history/index.html#mycin-key-features-and-functionality",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "MYCIN: Key Features and Functionality",
    "text": "MYCIN: Key Features and Functionality\n\nRule-based system with approximately 600 rules\nUsed backward chaining inference engine\nIncorporated certainty factors to handle uncertainty\nAsked users a series of yes/no questions about symptoms and test results\nProvided diagnosis recommendations and suggested antibiotic treatments\nExplained its reasoning process to user"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#mycin-impact-and-legacy",
    "href": "2024-10-30-ai-history/index.html#mycin-impact-and-legacy",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "MYCIN: Impact and Legacy",
    "text": "MYCIN: Impact and Legacy\n\nNever used in clinical practice due to ethical and legal concerns\nAchieved performance comparable to human experts in its domain\nPioneered several important concepts in AI and expert systems:\n\nSeparation of knowledge base from inference engine\nExplanation of reasoning\nHandling of uncertainty\n\nInfluenced development of subsequent expert systems and clinical decision support tools\nDemonstrated potential of AI in healthcare, paving way for modern medical AI applications"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#increased-computational-power",
    "href": "2024-10-30-ai-history/index.html#increased-computational-power",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Increased Computational Power",
    "text": "Increased Computational Power\n\nAdvancement:\n\nRapid growth of CPUs and the emergence of GPUs (Graphics Processing Units).\n\nImpact:\n\nEnabled the training of deeper neural networks essential for various AI tasks."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#big-data",
    "href": "2024-10-30-ai-history/index.html#big-data",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Big Data",
    "text": "Big Data\n\nAdvancement:\n\nExplosion of digital data from the internet, social media, and sensors.\n\nImpact:\n\nFacilitated the development of accurate models as ML algorithms require substantial data to learn effectively."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#open-source-frameworks-and-libraries",
    "href": "2024-10-30-ai-history/index.html#open-source-frameworks-and-libraries",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Open Source Frameworks and Libraries",
    "text": "Open Source Frameworks and Libraries\n\nAdvancement:\n\nEmergence of libraries like TensorFlow (2015), Keras (2015), and Scikit-learn (2007).\n\nImpact:\n\nLowered the barrier for AI development, allowing more practitioners to innovate in the field."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#advances-in-algorithms",
    "href": "2024-10-30-ai-history/index.html#advances-in-algorithms",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Advances in Algorithms",
    "text": "Advances in Algorithms\n\nAdvancement:\n\nResearch in new algorithms, such as support vector machines and deep learning architectures.\n\nImpact:\n\nImproved AI performance across applications, particularly in image and speech recognition."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#cloud-computing",
    "href": "2024-10-30-ai-history/index.html#cloud-computing",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Cloud Computing",
    "text": "Cloud Computing\n\nAdvancement:\n\nRise of cloud computing platforms (e.g., AWS, Google Cloud, Microsoft Azure).\n\nImpact:\n\nProvided scalable resources for storage and computation, enabling extensive ML experimentation."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#collaborative-research-and-knowledge-sharing",
    "href": "2024-10-30-ai-history/index.html#collaborative-research-and-knowledge-sharing",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Collaborative Research and Knowledge Sharing",
    "text": "Collaborative Research and Knowledge Sharing\n\nAdvancement:\n\nIncreased collaboration and sharing of findings through conferences and online platforms.\n\nImpact:\n\nAccelerated innovation in AI and ML as researchers built upon each other’s work."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#investment-and-interest-from-industry",
    "href": "2024-10-30-ai-history/index.html#investment-and-interest-from-industry",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Investment and Interest from Industry",
    "text": "Investment and Interest from Industry\n\nAdvancement:\n\nGrowing interest and investment from tech giants and startups in AI technologies.\n\nImpact:\n\nLed to the development of practical applications and commercial products, driving further research."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#deep-learning-resurgence-2006",
    "href": "2024-10-30-ai-history/index.html#deep-learning-resurgence-2006",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Deep Learning Resurgence (2006)",
    "text": "Deep Learning Resurgence (2006)\n\nMilestone: Geoffrey Hinton and team introduced “deep belief networks.”\nImpact: Marked the resurgence of deep learning and laid the foundation for modern AI applications, especially in image and speech recognition."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#alexnet-wins-imagenet-competition-2012",
    "href": "2024-10-30-ai-history/index.html#alexnet-wins-imagenet-competition-2012",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "AlexNet Wins ImageNet Competition (2012)",
    "text": "AlexNet Wins ImageNet Competition (2012)\n\nMilestone: Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton’s deep neural network (AlexNet) won the ImageNet competition.\nImpact: Showcased the power of convolutional neural networks (CNNs) and triggered widespread adoption in computer vision tasks."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#ibm-watson-wins-jeopardy-2011",
    "href": "2024-10-30-ai-history/index.html#ibm-watson-wins-jeopardy-2011",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "IBM Watson Wins Jeopardy! (2011)",
    "text": "IBM Watson Wins Jeopardy! (2011)\n\nMilestone: IBM Watson defeated champions Ken Jennings and Brad Rutter on Jeopardy!.\nImpact: Demonstrated AI’s ability to process and understand natural language, leading to applications in healthcare, finance, and customer service."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#md-anderson-sets-watson-aside-2017-2018",
    "href": "2024-10-30-ai-history/index.html#md-anderson-sets-watson-aside-2017-2018",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "MD Anderson sets Watson aside (2017-2018)",
    "text": "MD Anderson sets Watson aside (2017-2018)\n\nSee Herper (n.d.)"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#generative-adversarial-networks-gans-2014",
    "href": "2024-10-30-ai-history/index.html#generative-adversarial-networks-gans-2014",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Generative Adversarial Networks (GANs) (2014)",
    "text": "Generative Adversarial Networks (GANs) (2014)\n\nMilestone: Ian Goodfellow introduced GANs, a model where two neural networks compete to generate realistic data.\nImpact: Revolutionized image generation and unsupervised learning, powering innovations like deepfakes and AI-generated art."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#alphago-defeats-world-champion-2016",
    "href": "2024-10-30-ai-history/index.html#alphago-defeats-world-champion-2016",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "AlphaGo Defeats World Champion (2016)",
    "text": "AlphaGo Defeats World Champion (2016)\n\nMilestone: Google DeepMind’s AlphaGo defeated Go champion Lee Sedol.\nImpact: Showcased the capability of reinforcement learning and deep neural networks in mastering complex strategic games."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#transformer-architecture-2017",
    "href": "2024-10-30-ai-history/index.html#transformer-architecture-2017",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Transformer Architecture (2017)",
    "text": "Transformer Architecture (2017)\n\nMilestone: Vaswani et al. introduced the Transformer model, revolutionizing natural language processing.\nImpact: Laid the groundwork for state-of-the-art NLP models like BERT and GPT, transforming language understanding and generation."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#alphafold-solves-protein-folding-2020",
    "href": "2024-10-30-ai-history/index.html#alphafold-solves-protein-folding-2020",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "AlphaFold Solves Protein Folding (2020)",
    "text": "AlphaFold Solves Protein Folding (2020)\n\nMilestone: DeepMind’s AlphaFold achieved breakthrough accuracy in predicting protein structures.\nImpact: Solved a 50-year-old challenge in biology, opening new doors in drug discovery and molecular biology."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#gpt-4-and-large-language-models-2023",
    "href": "2024-10-30-ai-history/index.html#gpt-4-and-large-language-models-2023",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "GPT-4 and Large Language Models (2023)",
    "text": "GPT-4 and Large Language Models (2023)\n\nMilestone: OpenAI’s GPT-4 showcased the potential of large-scale language models for complex, nuanced language understanding.\nImpact: Accelerated the development of AI-driven content creation and enhanced human-computer interaction."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#impact",
    "href": "2024-10-30-ai-history/index.html#impact",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Impact",
    "text": "Impact\n\n\n\n\n\nNobel prize in chemistry\n\n\n\n\n\n\nNobel prize in physics"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#future-directions",
    "href": "2024-10-30-ai-history/index.html#future-directions",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Future Directions",
    "text": "Future Directions\n\nArtificial General Intelligence (AGI) research\nQuantum computing and AI\nNeuromorphic computing\nHuman-AI collaboration\n\nFor deeper dive into the history, see (Norman 2024)."
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#challenges-and-opportunities",
    "href": "2024-10-30-ai-history/index.html#challenges-and-opportunities",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Challenges and Opportunities",
    "text": "Challenges and Opportunities\n\nEthical AI development\nAI governance and regulation\nAddressing AI bias and fairness\nBalancing innovation with responsible development"
  },
  {
    "objectID": "2024-10-30-ai-history/index.html#references",
    "href": "2024-10-30-ai-history/index.html#references",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "References",
    "text": "References\n\n\n\n\nAsimov, Isaac. 1950. I, Robot. Bantam hardcover ed. (2). New York: Bantam Books.\n\n\nHerper, Matthew. n.d. “MD Anderson Benches IBM Watson In Setback For Artificial Intelligence In Medicine.” Forbes. Accessed October 2, 2024. https://www.forbes.com/sites/matthewherper/2017/02/19/md-anderson-benches-ibm-watson-in-setback-for-artificial-intelligence-in-medicine/.\n\n\nNorman, Jeremy. 2024. “History of Information.” https://www.historyofinformation.com/?cat=71.\n\n\nTuring, Alan. 1936. “On Computable Numbers, with an Application to the Entscheidungsproblem.” https://www.abelard.org/turpap2/tp2-ie.asp.\n\n\n———. 1950. “Computing Machinery and Intelligence.” Mind 59 (October): 433–60. https://doi.org/10.1093/mind/lix.236.433."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Talks and Presentations",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nThe History of Artificial Intelligence and Machine Learning\n\n\n\n\n\n\nSean Davis, MD, PhD\n\n\nOctober 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI in the Oncology Service Line\n\n\n\n\n\n\nSean Davis, MD, PhD\n\n\nOctober 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI in Medical Education\n\n\n\n\n\n\nSean Davis, MD, PhD\n\n\nOctober 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI Agents\n\n\nLearn how large language models can be used as agents to solve complex tasks by interacting with external tools.\n\n\n\nSean Davis, MD, PhD\n\n\nOctober 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Engineering\n\n\nLearn design principles for effective prompts for language models to improve accuracy, usability, and relevance of model outputs.\n\n\n\nSean Davis, MD, PhD\n\n\nOctober 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Machine Learning\n\n\n\n\n\n\nSean Davis, MD, PhD\n\n\nSeptember 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe History of Artificial Intelligence and Machine Learning\n\n\n\n\n\n\nSean Davis, MD, PhD\n\n\nSeptember 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nData products and partnerships\n\n\n\n\n\n\nSean Davis, MD, PhD\n\n\nAugust 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial Intelligence & Machine Learning\n\n\n\n\n\n\nSean Davis, MD, PhD\n\n\nNovember 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial Intelligence & Machine Learning\n\n\n\n\n\n\nSean Davis, MD, PhD\n\n\nJuly 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nReproducible, reusable, and shareable concepts in computational research\n\n\n\n\n\n\nSean Davis, MD, PhD\n\n\nMarch 9, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial Intelligence & Machine Learning\n\n\n\n\n\n\nSean Davis, MD, PhD\n\n\nSeptember 7, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "2024-10-17-prompt-engineering/index.html#what-is-a-prompt-anyway",
    "href": "2024-10-17-prompt-engineering/index.html#what-is-a-prompt-anyway",
    "title": "Prompt Engineering",
    "section": "What is a Prompt, anyway?",
    "text": "What is a Prompt, anyway?\n\nA prompt is a set of instructions or guidelines given to a language model to generate a specific output.\nIt can be a question, a task, or a description of the desired output.\nPrompts help guide the model’s response and ensure it provides relevant and accurate information.\nEffective prompt design is crucial for obtaining useful and reliable results from language models."
  },
  {
    "objectID": "2024-10-17-prompt-engineering/index.html#and-prompt-engineering",
    "href": "2024-10-17-prompt-engineering/index.html#and-prompt-engineering",
    "title": "Prompt Engineering",
    "section": "And Prompt Engineering?",
    "text": "And Prompt Engineering?\n\nPrompt engineering is the process of designing prompts to elicit the desired responses from language models.\nIt involves crafting clear, specific, and structured instructions that guide the model’s behavior.\nWell-designed prompts can improve the accuracy, relevance, and usability of the model’s outputs.\nPrompt engineering is essential for leveraging the full potential of language models in various applications."
  },
  {
    "objectID": "2024-10-17-prompt-engineering/index.html#rule-1-start-with-a-clear-objective",
    "href": "2024-10-17-prompt-engineering/index.html#rule-1-start-with-a-clear-objective",
    "title": "Prompt Engineering",
    "section": "Rule 1: Start with a Clear Objective",
    "text": "Rule 1: Start with a Clear Objective\nWhy? A well-defined goal guides the prompting process.\nHow? Begin with a specific question, task, or instruction.\nExample:\n❌ \"Tell me about diabetes.\" \n\n✅ \"Summarize the key risk factors for developing Type 2 diabetes.\""
  },
  {
    "objectID": "2024-10-17-prompt-engineering/index.html#rule-2-provide-context",
    "href": "2024-10-17-prompt-engineering/index.html#rule-2-provide-context",
    "title": "Prompt Engineering",
    "section": "Rule 2: Provide Context",
    "text": "Rule 2: Provide Context\nWhy? Context helps the model understand the background and purpose.\nHow? Include relevant details such as patient demographics, medical history, or specific symptoms.\nExample:\n✅ “A 55-year-old male with a history of hypertension presents with chest pain…”"
  },
  {
    "objectID": "2024-10-17-prompt-engineering/index.html#rule-3-use-precise-language",
    "href": "2024-10-17-prompt-engineering/index.html#rule-3-use-precise-language",
    "title": "Prompt Engineering",
    "section": "Rule 3: Use Precise Language",
    "text": "Rule 3: Use Precise Language\nWhy? Ambiguity can lead to inaccurate or irrelevant results.\nHow? Choose specific medical terms and avoid vague descriptions.\nExample:\n❌ “stomach pain”\n✅ “epigastric pain radiating to the back”"
  },
  {
    "objectID": "2024-10-17-prompt-engineering/index.html#rule-4-specify-the-desired-output-format",
    "href": "2024-10-17-prompt-engineering/index.html#rule-4-specify-the-desired-output-format",
    "title": "Prompt Engineering",
    "section": "Rule 4: Specify the Desired Output Format",
    "text": "Rule 4: Specify the Desired Output Format\nWhy? This ensures the information is delivered in a usable format.\nHow? Request specific formats like lists, tables, summaries, or code.\nExample:\n✅ “Generate a differential diagnosis list for these symptoms…”\n✅ “Summarize the patient’s history in bullet points.”"
  },
  {
    "objectID": "2024-10-17-prompt-engineering/index.html#rule-5-iterate-and-refine",
    "href": "2024-10-17-prompt-engineering/index.html#rule-5-iterate-and-refine",
    "title": "Prompt Engineering",
    "section": "Rule 5: Iterate and Refine",
    "text": "Rule 5: Iterate and Refine\nWhy? Prompt engineering is an iterative process.\nHow? Experiment with different phrasing, keywords, and levels of detail. Analyze the outputs and refine the prompts to improve accuracy.\nExample:\n\nInitial Prompt: “What are the treatment options for this patient?”\nRefined Prompt: “Given the patient’s age, medical history, and contraindications, provide a prioritized list of evidence-based treatment options for their condition.”"
  },
  {
    "objectID": "2024-10-17-prompt-engineering/index.html#rule-6-employ-few-shot-prompting",
    "href": "2024-10-17-prompt-engineering/index.html#rule-6-employ-few-shot-prompting",
    "title": "Prompt Engineering",
    "section": "Rule 6: Employ “Few-Shot” Prompting",
    "text": "Rule 6: Employ “Few-Shot” Prompting\nWhy? Providing examples helps the model understand the desired pattern.\nHow? Include a few examples of the desired input-output pairs in the prompt.\nExample:\nPrompt: “Translate these medical abbreviations:\n\nCHF: Congestive Heart Failure\nMI: Myocardial Infarction\n\nNow translate:\n\nCOPD: ”"
  },
  {
    "objectID": "2024-10-17-prompt-engineering/index.html#rule-7-break-down-complex-tasks",
    "href": "2024-10-17-prompt-engineering/index.html#rule-7-break-down-complex-tasks",
    "title": "Prompt Engineering",
    "section": "Rule 7: Break Down Complex Tasks",
    "text": "Rule 7: Break Down Complex Tasks\nWhy? Large language models perform better with focused, step-by-step instructions.\nHow? Decompose complex tasks into smaller, more manageable subtasks.\nExample:\nInstead of asking for a complete treatment plan, first ask for:\n\nPossible diagnoses\nTreatment options for each diagnosis\nFactors influencing treatment selection"
  },
  {
    "objectID": "2024-10-17-prompt-engineering/index.html#rule-8-utilize-delimiters",
    "href": "2024-10-17-prompt-engineering/index.html#rule-8-utilize-delimiters",
    "title": "Prompt Engineering",
    "section": "Rule 8: Utilize Delimiters",
    "text": "Rule 8: Utilize Delimiters\nWhy? Delimiters help the model distinguish between different parts of the prompt.\nHow? Use clear separators like “```”, “###”, or “**” to mark different sections.\nExample:\nPrompt:\nYour goal is to generate a differential diagnosis for this patient. \n\n### Start of patient information\nPatient History:\n60-year-old female\nHistory of type 2 diabetes\n\nCurrent Symptoms:\nFatigue\nIncreased thirst\n### End of patient information"
  },
  {
    "objectID": "2024-10-17-prompt-engineering/index.html#rule-9-be-mindful-of-biases",
    "href": "2024-10-17-prompt-engineering/index.html#rule-9-be-mindful-of-biases",
    "title": "Prompt Engineering",
    "section": "Rule 9: Be Mindful of Biases",
    "text": "Rule 9: Be Mindful of Biases\nWhy? Language models can reflect biases present in the training data.\nHow? Use neutral language and avoid stereotypes.\nExample:\n❌ “This is a typical case of…”\n✅ “Based on the presented information, consider…”"
  },
  {
    "objectID": "2024-10-17-prompt-engineering/index.html#rule-10-stay-updated-on-best-practices",
    "href": "2024-10-17-prompt-engineering/index.html#rule-10-stay-updated-on-best-practices",
    "title": "Prompt Engineering",
    "section": "Rule 10: Stay Updated on Best Practices",
    "text": "Rule 10: Stay Updated on Best Practices\n\nOpenAI’s prompt engineering guide\nGoogle’s prompt design strategies\nPublicly available prompt repositories\n\nhttps://github.com/abilzerian/LLM-Prompt-Library\n\nhttps://www.promptingguide.ai/\nhttps://promptengineering.org/\nResearch papers: Meskó (2023)"
  },
  {
    "objectID": "2024-10-17-prompt-engineering/index.html#references",
    "href": "2024-10-17-prompt-engineering/index.html#references",
    "title": "Prompt Engineering",
    "section": "References",
    "text": "References\n\n\n\n\nMeskó, Bertalan. 2023. “Prompt Engineering as an Important Emerging Skill for Medical Professionals: Tutorial.” Journal of Medical Internet Research 25 (1): e50638. https://doi.org/10.2196/50638."
  },
  {
    "objectID": "2023-11-27-CUNY-json-data/index.html#flatiron",
    "href": "2023-11-27-CUNY-json-data/index.html#flatiron",
    "title": "Data products and partnerships",
    "section": "Flatiron",
    "text": "Flatiron\nFlatiron Health is a healthcare technology and services company focused on accelerating cancer research and improving patient care. The company’s platform enables cancer researchers and care providers to learn from the experience of every patient."
  },
  {
    "objectID": "2023-11-27-CUNY-json-data/index.html#flatiron-1",
    "href": "2023-11-27-CUNY-json-data/index.html#flatiron-1",
    "title": "Data products and partnerships",
    "section": "Flatiron",
    "text": "Flatiron\n\n~3.5M patients\n~25 diseases\n~100 clinics and academic centers\n\nResearch proposals accepted on a rolling basis from any CU faculty member. Proposals are reviewed by a joint steering committee."
  },
  {
    "objectID": "2023-11-27-CUNY-json-data/index.html#cancerlinqconcertai",
    "href": "2023-11-27-CUNY-json-data/index.html#cancerlinqconcertai",
    "title": "Data products and partnerships",
    "section": "CancerLinQ/ConcertAI",
    "text": "CancerLinQ/ConcertAI\nCancerLinQ is a health information technology platform that collects and analyzes real-world cancer data to improve the quality of care for patients with cancer. CancerLinQ was, until recently, a wholly owned nonprofit subsidiary of the American Society of Clinical Oncology (ASCO). In 2021, CancerLinQ was acquired by ConcertAI, a leading provider of real-world data and AI technologies for oncology."
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#beyond-text-llms-as-agents",
    "href": "2024-10-17-ai-agents-and-llms/index.html#beyond-text-llms-as-agents",
    "title": "AI Agents",
    "section": "Beyond Text: LLMs as Agents",
    "text": "Beyond Text: LLMs as Agents\n\nTraditional LLMs excel at text generation, but their knowledge is limited to their training data.\nTool use allows LLMs to become active agents, interacting with the real world.\nExamples: retrieving up-to-date information, performing calculations, running code, controlling software."
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#when-rag-is-not-enough",
    "href": "2024-10-17-ai-agents-and-llms/index.html#when-rag-is-not-enough",
    "title": "AI Agents",
    "section": "When RAG is not enough",
    "text": "When RAG is not enough"
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#the-rationale-for-tool-use",
    "href": "2024-10-17-ai-agents-and-llms/index.html#the-rationale-for-tool-use",
    "title": "AI Agents",
    "section": "The Rationale for Tool Use",
    "text": "The Rationale for Tool Use\n\nOvercoming Knowledge Limitations: Accessing external data sources like the internet or specific databases keeps the LLM’s knowledge current and relevant.\nEnhancing Capabilities: Tools allow LLMs to perform tasks they cannot do independently, like booking a flight or controlling a smart home device.\nImproving Accuracy: Using tools for tasks like calculations or fact-checking ensures more reliable outputs."
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#components-of-llm-tools",
    "href": "2024-10-17-ai-agents-and-llms/index.html#components-of-llm-tools",
    "title": "AI Agents",
    "section": "Components of LLM Tools",
    "text": "Components of LLM Tools\n\nAPI: The interface that allows the LLM to communicate with the tool.\nDescription: A clear definition of the tool’s function, inputs, and outputs. This allows the LLM to understand how to use the tool correctly.\nInvoker: A mechanism that triggers the tool based on the LLM’s instructions."
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#what-is-an-api",
    "href": "2024-10-17-ai-agents-and-llms/index.html#what-is-an-api",
    "title": "AI Agents",
    "section": "What is an API?",
    "text": "What is an API?\n\nAPI stands for Application Programming Interface.\nIt’s a set of rules and specifications that allow one application to access the features or data of another application.\nThis enables different applications to communicate and interact with each other."
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#apis-and-llm-tools",
    "href": "2024-10-17-ai-agents-and-llms/index.html#apis-and-llm-tools",
    "title": "AI Agents",
    "section": "APIs and LLM Tools",
    "text": "APIs and LLM Tools\n\nAPIs are the foundation of LLM tool use.\nThey provide the communication channel between the LLM and the external tool.\nThe LLM uses the API to send requests to the tool and receive responses."
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#how-llms-use-tools",
    "href": "2024-10-17-ai-agents-and-llms/index.html#how-llms-use-tools",
    "title": "AI Agents",
    "section": "How LLMs Use Tools",
    "text": "How LLMs Use Tools\n\nTask Identification: The LLM analyzes the user’s request and determines if a tool is needed.\nTool Selection: The LLM selects the appropriate tool based on the task and the available tools.\nAPI Call Formulation: The LLM generates the correct API call to the selected tool, including any necessary parameters.\nResponse Integration: The LLM receives the tool’s output and integrates it into its response to the user."
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#structured-output-json",
    "href": "2024-10-17-ai-agents-and-llms/index.html#structured-output-json",
    "title": "AI Agents",
    "section": "Structured Output (JSON)",
    "text": "Structured Output (JSON)\n\nJSON stands for JavaScript Object Notation.\nIt’s a lightweight data format that is easy for humans to read and write and easy for machines to parse.\nJSON is commonly used for transmitting data between web applications and servers."
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#json-and-llm-tools",
    "href": "2024-10-17-ai-agents-and-llms/index.html#json-and-llm-tools",
    "title": "AI Agents",
    "section": "JSON and LLM Tools",
    "text": "JSON and LLM Tools\n\nMany LLM tools use JSON for input and output.\nThe LLM sends requests to the tool in JSON format.\nThe tool responds with results in JSON format, which the LLM can then process."
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#benefits-of-using-json",
    "href": "2024-10-17-ai-agents-and-llms/index.html#benefits-of-using-json",
    "title": "AI Agents",
    "section": "Benefits of Using JSON",
    "text": "Benefits of Using JSON\n\nStandardized Format: Ensures consistency and compatibility between different tools.\nEasy to Parse: Allows the LLM to quickly extract the information it needs from the tool’s response.\nFlexible: Can represent a wide range of data structures."
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#llms-as-components-of-larger-systems",
    "href": "2024-10-17-ai-agents-and-llms/index.html#llms-as-components-of-larger-systems",
    "title": "AI Agents",
    "section": "LLMs as components of larger systems",
    "text": "LLMs as components of larger systems"
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#planning",
    "href": "2024-10-17-ai-agents-and-llms/index.html#planning",
    "title": "AI Agents",
    "section": "Planning",
    "text": "Planning"
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#memory",
    "href": "2024-10-17-ai-agents-and-llms/index.html#memory",
    "title": "AI Agents",
    "section": "Memory",
    "text": "Memory"
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#tools",
    "href": "2024-10-17-ai-agents-and-llms/index.html#tools",
    "title": "AI Agents",
    "section": "Tools",
    "text": "Tools"
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#future-of-llm-tool-use",
    "href": "2024-10-17-ai-agents-and-llms/index.html#future-of-llm-tool-use",
    "title": "AI Agents",
    "section": "Future of LLM Tool Use",
    "text": "Future of LLM Tool Use\n\nMore Sophisticated Tools: LLMs will be able to use a wider range of tools, including those that can perform more complex tasks.\nImproved Integration: LLMs will be able to seamlessly integrate tool outputs into their responses.\nIncreased Autonomy: LLMs will be able to make more decisions about when and how to use tools."
  },
  {
    "objectID": "2024-10-17-ai-agents-and-llms/index.html#llm-tool-use-in-healthcare",
    "href": "2024-10-17-ai-agents-and-llms/index.html#llm-tool-use-in-healthcare",
    "title": "AI Agents",
    "section": "LLM Tool Use in Healthcare",
    "text": "LLM Tool Use in Healthcare\n\nPotential Applications: Accessing patient records, retrieving medical research, generating reports, scheduling appointments.\nBenefits: Improved efficiency, accuracy, and decision-making.\nChallenges: Ensuring patient privacy and data security."
  },
  {
    "objectID": "tech-examples/llm-intro.html#word-embeddings",
    "href": "tech-examples/llm-intro.html#word-embeddings",
    "title": "What are Large Language Models, anyway?",
    "section": "Word embeddings",
    "text": "Word embeddings"
  },
  {
    "objectID": "tech-examples/llm-intro.html#training",
    "href": "tech-examples/llm-intro.html#training",
    "title": "What are Large Language Models, anyway?",
    "section": "Training",
    "text": "Training\n\n\nCol 1\n\nCol 2\n\nCol 3\n\nCol 4"
  },
  {
    "objectID": "tech-examples/llm-intro.html#training-1",
    "href": "tech-examples/llm-intro.html#training-1",
    "title": "What are Large Language Models, anyway?",
    "section": "Training",
    "text": "Training\n\n\nCol 1"
  },
  {
    "objectID": "tech-examples/llm-intro.html#training-2",
    "href": "tech-examples/llm-intro.html#training-2",
    "title": "What are Large Language Models, anyway?",
    "section": "Training",
    "text": "Training\n\n\nCol 1\n\nCol 2\n\nCol 3\n\nCol 4"
  },
  {
    "objectID": "tech-examples/llm-intro.html#section-1",
    "href": "tech-examples/llm-intro.html#section-1",
    "title": "What are Large Language Models, anyway?",
    "section": "",
    "text": "Large, general-purpose language models pre-trained on large corpora of text data that can be fine-tuned for specific purposes."
  },
  {
    "objectID": "tech-examples/llm-intro.html#section-2",
    "href": "tech-examples/llm-intro.html#section-2",
    "title": "What are Large Language Models, anyway?",
    "section": "",
    "text": "Language Models, anyway?"
  },
  {
    "objectID": "tech-examples/llm-intro.html#what-is-pre-training",
    "href": "tech-examples/llm-intro.html#what-is-pre-training",
    "title": "What are Large Language Models, anyway?",
    "section": "What is pre-training?",
    "text": "What is pre-training?\n\n\nStay!\n\n\nCome!\n\n\nSit!\n\n\nBeg!\n\n\n\nOur dog has received general-purpose training and is a good canine citizen."
  },
  {
    "objectID": "tech-examples/llm-intro.html#section-3",
    "href": "tech-examples/llm-intro.html#section-3",
    "title": "What are Large Language Models, anyway?",
    "section": "",
    "text": "Animating content"
  },
  {
    "objectID": "tech-examples/llm-intro.html#section-4",
    "href": "tech-examples/llm-intro.html#section-4",
    "title": "What are Large Language Models, anyway?",
    "section": "",
    "text": "Animating content"
  },
  {
    "objectID": "tech-examples/llm-intro.html#title",
    "href": "tech-examples/llm-intro.html#title",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\nFine-tuning is the process of training a model on a specific task or dataset."
  },
  {
    "objectID": "tech-examples/llm-intro.html#title-1",
    "href": "tech-examples/llm-intro.html#title-1",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\nFine-tuning is the process of training a model on a specific task or dataset."
  },
  {
    "objectID": "tech-examples/llm-intro.html#title-2",
    "href": "tech-examples/llm-intro.html#title-2",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\nFine-tuning is the process of training a model on a specific task or dataset."
  },
  {
    "objectID": "tech-examples/llm-intro.html#title-3",
    "href": "tech-examples/llm-intro.html#title-3",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\nFine-tuning is the process of training a model on a specific task or dataset."
  },
  {
    "objectID": "tech-examples/llm-intro.html#title-4",
    "href": "tech-examples/llm-intro.html#title-4",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\nFine-tuning is the process of training a model on a specific task or dataset.\nGeneral-purpose models can be fine-tuned for specific tasks."
  },
  {
    "objectID": "tech-examples/llm-intro.html#title-5",
    "href": "tech-examples/llm-intro.html#title-5",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\n\nFine-tuning is the process of training a model on a specific task or dataset.\n\n\n\nGeneral-purpose models can be fine-tuned for specific tasks."
  },
  {
    "objectID": "tech-examples/llm-intro.html#title-6",
    "href": "tech-examples/llm-intro.html#title-6",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\n\nFine-tuning is the process of training a model on a specific task or dataset.\nGeneral-purpose models can be fine-tuned for specific tasks."
  },
  {
    "objectID": "tech-examples/llm-intro.html#title-7",
    "href": "tech-examples/llm-intro.html#title-7",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\n\n\n\nFine-tuning is the process of training a model on a specific task or dataset.\n\n\n\nGeneral-purpose models can be fine-tuned for specific tasks.\n\n\n\naGeneral-purpose models can be fine-tuned for specific tasks."
  },
  {
    "objectID": "tech-examples/llm-intro.html#title-8",
    "href": "tech-examples/llm-intro.html#title-8",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\n\n\n\nFine-tuning is the process of training a model on a specific task or dataset.\n\n\n\nGeneral-purpose models can be fine-tuned for specific tasks.\n\n\n\naGeneral-purpose models can be fine-tuned for specific tasks."
  },
  {
    "objectID": "tech-examples/llm-intro.html#title-9",
    "href": "tech-examples/llm-intro.html#title-9",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\n\n\n\nFine-tuning is the process of training a model on a specific task or dataset.\n\n\n\nGeneral-purpose models can be fine-tuned for specific tasks.\n\n\n\naGeneral-purpose models can be fine-tuned for specific tasks."
  },
  {
    "objectID": "tech-examples/llm-intro.html#section-5",
    "href": "tech-examples/llm-intro.html#section-5",
    "title": "What are Large Language Models, anyway?",
    "section": "",
    "text": "Linear combinations of dimensions in vector space correlate with the semantic and syntactic roles of the words in the corpus. For illustration purposes, dimension d1 in the figure has a high positive correlation with living beings. A properly tuned word embedding model will map words with similar semantic or syntactic roles to adjacent regions in vector space. This property can be visualized through dimensionality reduction techniques such as t-SNE or PCA. Cultural concepts are also apparent in vector space as consistent offsets between vector representations of words sharing a particular relationship. For instance, in the bottom right of the figure, the dotted vector represents a gender regularity that goes from masculinity to femininity."
  },
  {
    "objectID": "tech-examples/llm-intro.html#section-6",
    "href": "tech-examples/llm-intro.html#section-6",
    "title": "What are Large Language Models, anyway?",
    "section": "",
    "text": "Which dimension shows a strong correlation with masculinity-femininity?\n\n\n\n\nAnd what about royalty-commoner?\n\n\n\n\nHow about dog-cat?\n\n\n\n\nGiven the answer to the above, what might be an approximate value of the dog-cat dimension for kitten?"
  }
]